{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§  Mouse Model Tutorial\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](\n",
    "https://colab.research.google.com/github/mouseland/minimodel/blob/master/notebooks/mouse_pipeline.ipynb)\n",
    "\n",
    "Welcome! This notebook walks through the training pipeline for the mouse model.\n",
    "\n",
    "You'll start by training the full model using data from all neurons of a sample mouse.\n",
    "\n",
    "Then, you'll train a minimodel that focuses on predicting the response of a single neuron from the same dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Install dependencies (run if using colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ› ï¸ Install minimodel and dependencies\n",
    "!pip install --no-deps git+https://github.com/mouseland/minimodel.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data directory\n",
    "!mkdir -p data\n",
    "!mkdir -p checkpoints\n",
    "\n",
    "# Download both files\n",
    "!wget -O data/FX10_nat60k_2023_05_16.npz https://janelia.figshare.com/ndownloader/files/53712311\n",
    "!wget -O data/nat60k_text16.mat https://janelia.figshare.com/ndownloader/files/53678783\n",
    "!wget -O checkpoints/FX8_051623_2layer_16_320_clamp_norm_depthsep_pool.pt https://github.com/MouseLand/minimodel/releases/download/V1.0.0/FX8_051623_2layer_16_320_clamp_norm_depthsep_pool.pt\n",
    "!wget -O checkpoints/FX8_051623_2layer_16_64_clamp_norm_depthsep_pool_nn3218_hs3e-02.pt https://github.com/MouseLand/minimodel/releases/download/V1.0.0/FX8_051623_2layer_16_64_clamp_norm_depthsep_pool_nn3218_hs3e-02.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. load data\n",
    "load images and the neural activity, then split the data into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from minimodel import data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_id = 4\n",
    "\n",
    "data_path = './data'\n",
    "weight_path = './checkpoints'\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images\n",
    "img = data.load_images(data_path, mouse_id, file=data.img_file_name[mouse_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load neurons\n",
    "fname = '%s_nat60k_%s.npz'%(data.db[mouse_id]['mname'], data.db[mouse_id]['datexp'])\n",
    "spks, istim_train, istim_test, xpos, ypos, spks_rep_all = data.load_neurons(file_path = os.path.join(data_path, fname), mouse_id = mouse_id)\n",
    "n_stim, n_neurons = spks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and validation set\n",
    "itrain, ival = data.split_train_val(istim_train, train_frac=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "spks, spks_rep_all = data.normalize_spks(spks, spks_rep_all, itrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ineur = np.arange(0, n_neurons) #np.arange(0, n_neurons, 5)\n",
    "spks_train = torch.from_numpy(spks[itrain][:,ineur])\n",
    "spks_val = torch.from_numpy(spks[ival][:,ineur]) \n",
    "\n",
    "print('spks_train: ', spks_train.shape, spks_train.min(), spks_train.max())\n",
    "print('spks_val: ', spks_val.shape, spks_val.min(), spks_val.max())\n",
    "\n",
    "img_train = torch.from_numpy(img[istim_train][itrain]).to(device).unsqueeze(1) # change :130 to 25:100 \n",
    "img_val = torch.from_numpy(img[istim_train][ival]).to(device).unsqueeze(1)\n",
    "img_test = torch.from_numpy(img[istim_test]).to(device).unsqueeze(1)\n",
    "\n",
    "print('img_train: ', img_train.shape, img_train.min(), img_train.max())\n",
    "print('img_val: ', img_val.shape, img_val.min(), img_val.max())\n",
    "print('img_test: ', img_test.shape, img_test.min(), img_test.max())\n",
    "\n",
    "input_Ly, input_Lx = img_train.shape[-2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. fullmodel\n",
    "build the two-layer full model (16-320) then train and test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "from minimodel import model_builder\n",
    "nlayers = 2\n",
    "nconv1 = 16\n",
    "nconv2 = 320\n",
    "fullmodel, in_channels = model_builder.build_model(NN=len(ineur), n_layers=nlayers, n_conv=nconv1, n_conv_mid=nconv2)\n",
    "model_name = model_builder.create_model_name(data.mouse_names[mouse_id], data.exp_date[mouse_id], n_layers=nlayers, in_channels=in_channels)\n",
    "\n",
    "model_path = os.path.join(weight_path, model_name)\n",
    "fullmodel = fullmodel.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "from minimodel import model_trainer\n",
    "if not os.path.exists(model_path):\n",
    "    best_state_dict = model_trainer.train(fullmodel, spks_train, spks_val, img_train, img_val, device=device)\n",
    "    torch.save(best_state_dict, model_path)\n",
    "    print('saved model', model_path)\n",
    "fullmodel.load_state_dict(torch.load(model_path))\n",
    "print('loaded model', model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model\n",
    "test_pred = model_trainer.test_epoch(fullmodel, img_test)\n",
    "print('test_pred: ', test_pred.shape, test_pred.min(), test_pred.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minimodel import metrics\n",
    "test_fev, test_feve = metrics.feve(spks_rep_all, test_pred)\n",
    "\n",
    "threshold = 0.15\n",
    "print(f'filtering neurons with FEV > {threshold}')\n",
    "valid_idxes = np.where(test_fev > threshold)[0]\n",
    "print(f'valid neurons: {len(valid_idxes)} / {len(test_fev)}')\n",
    "print(f'FEVE (test): {np.mean(test_feve[test_fev > threshold])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. minimodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "ineuron = 3218\n",
    "ineur = [ineuron]\n",
    "spks_train = torch.from_numpy(spks[itrain][:,ineur])\n",
    "spks_val = torch.from_numpy(spks[ival][:,ineur]) \n",
    "print('spks_train: ', spks_train.shape, spks_train.min(), spks_train.max())\n",
    "print('spks_val: ', spks_val.shape, spks_val.min(), spks_val.max())\n",
    "\n",
    "img_train = torch.from_numpy(img[istim_train][itrain]).to(device).unsqueeze(1) # change :130 to 25:100 \n",
    "img_val = torch.from_numpy(img[istim_train][ival]).to(device).unsqueeze(1)\n",
    "img_test = torch.from_numpy(img[istim_test]).to(device).unsqueeze(1)\n",
    "\n",
    "print('img_train: ', img_train.shape, img_train.min(), img_train.max())\n",
    "print('img_val: ', img_val.shape, img_val.min(), img_val.max())\n",
    "print('img_test: ', img_test.shape, img_test.min(), img_test.max())\n",
    "\n",
    "input_Ly, input_Lx = img_train.shape[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "from minimodel import model_builder\n",
    "nlayers = 2\n",
    "nconv1 = 16\n",
    "nconv2 = 64\n",
    "seed = 1\n",
    "hs_readout = 0.03\n",
    "wc_coef = 0.2\n",
    "model, in_channels = model_builder.build_model(NN=1, n_layers=nlayers, n_conv=nconv1, n_conv_mid=nconv2, Wc_coef=wc_coef)\n",
    "model_name = model_builder.create_model_name(data.mouse_names[mouse_id], data.exp_date[mouse_id], ineuron=ineur[0], n_layers=nlayers, in_channels=in_channels, seed=seed,hs_readout=hs_readout)\n",
    "\n",
    "model_path = os.path.join(weight_path, model_name)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "from minimodel import model_trainer\n",
    "if not os.path.exists(model_path):\n",
    "    model.core.features.layer0.conv.weight.data = fullmodel.core.features.layer0.conv.weight.data.clone()\n",
    "    model.core.features.layer0.conv.weight.requires_grad = False\n",
    "    best_state_dict = model_trainer.train(model, spks_train, spks_val, img_train, img_val, device=device, l2_readout=0.2, hs_readout=hs_readout, n_epochs_period=[30, 30, 30, 30])\n",
    "    torch.save(best_state_dict, model_path)\n",
    "    print('saved model', model_path)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "print('loaded model', model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model\n",
    "test_pred = model_trainer.test_epoch(model, img_test)\n",
    "print('test_pred: ', test_pred.shape, test_pred.min(), test_pred.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minimodel import metrics\n",
    "spks_rep = []\n",
    "for i in range(len(spks_rep_all)):\n",
    "    spks_rep.append(spks_rep_all[i][:,ineur])\n",
    "test_fev, test_feve = metrics.feve(spks_rep, test_pred)\n",
    "print('FEVE (test): ', np.mean(test_feve))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize conv1 weights\n",
    "conv1_w = model.core.features.layer0.conv.weight.data.cpu().numpy().squeeze()\n",
    "\n",
    "from minimodel.utils import conv1_isort_all\n",
    "conv1_isort = conv1_isort_all[mouse_id]\n",
    "fig, ax = plt.subplots(4, 4, figsize=(4,4))\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        ax[i, j].imshow(conv1_w[conv1_isort[i*4+j]], cmap='bwr', vmin=-0.5, vmax=0.5)\n",
    "        ax[i, j].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 check Wc\n",
    "Check the Wc weights in the readout, which determine the conv2 channels contribution to the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wc = model.readout.Wc.detach().cpu().numpy().squeeze()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3,3))\n",
    "ax.plot(np.sort(Wc))\n",
    "ax.set_title(f'Wc, #channels = {np.sum(np.abs(Wc) > 0.01)}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 visualize neuron\n",
    "Visualize the top stimuli of the neuron, and the top stimuli of the conv2 channels that contribute mostly to the neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the unique train images\n",
    "Nimgs_unique = img_train.shape[0]\n",
    "\n",
    "# get conv2 features of train images (in batches)\n",
    "model.eval()\n",
    "batch_size = 160\n",
    "nconv2 = 64\n",
    "conv2_fvs = np.zeros((Nimgs_unique, nconv2))\n",
    "for i in range(0, Nimgs_unique, batch_size):\n",
    "    images = img_train[i:i+batch_size].to(device)\n",
    "    conv2_fv = model.core(images)\n",
    "    wxy_fv = torch.einsum('iry, irx, ncyx -> ncr', model.readout.Wy, model.readout.Wx, conv2_fv).detach().cpu().numpy().squeeze()\n",
    "    conv2_fvs[i:i+batch_size] = wxy_fv\n",
    "\n",
    "# sort the features and select top 8 image for each channel\n",
    "fv_isort = np.argsort(-conv2_fvs, axis=0)\n",
    "Wc = model.readout.Wc.detach().cpu().numpy().squeeze()\n",
    "ivalid_Wc = np.where(np.abs(Wc)>0.01)[0]\n",
    "print('ivalid_Wc:', len(ivalid_Wc))\n",
    "fv_isort = fv_isort[:, ivalid_Wc]\n",
    "fv_isort_top8 = fv_isort[:8]\n",
    "Nimg, Nchannel = fv_isort_top8.shape\n",
    "\n",
    "# get mask of the images\n",
    "from minimodel.utils import get_image_mask\n",
    "ineuron_mask_up = get_image_mask(model, Ly=input_Ly, Lx=input_Lx)\n",
    "\n",
    "# get predictions from the training set\n",
    "neuron_activity_model = model_trainer.test_epoch(model, img_train)\n",
    "neuron_activity_model = neuron_activity_model.squeeze()\n",
    "prediction_isort = np.argsort(neuron_activity_model)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minimodel.utils import add_channel_frame\n",
    "\n",
    "# Parameters for the second plot\n",
    "pad = 5\n",
    "vmin = 0\n",
    "vmax = 255\n",
    "valid_wc = Wc[ivalid_Wc]\n",
    "isort = np.argsort(valid_wc)[::-1]\n",
    "Nchannel = 8\n",
    "# Combined plot layout\n",
    "fig = plt.figure(figsize=(Nimg * 2 + 20, Nchannel * 1.1))\n",
    "gs = plt.GridSpec(Nchannel, Nimg + 4, figure=fig, hspace=0.3, wspace=0.1, width_ratios=[1, 1, 1, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5])\n",
    "\n",
    "# Plot one (4x4 grid on the left side, occupying 2 rows per row)\n",
    "nshow = 16\n",
    "for i in range(nshow):\n",
    "    row = (i // 4) * 2\n",
    "    col = i % 4\n",
    "    ax = fig.add_subplot(gs[row:row + 2, col])\n",
    "    ax.imshow(img_train[prediction_isort[i]].cpu().numpy().squeeze() * ineuron_mask_up, cmap='gray', vmin=-1, vmax=1)\n",
    "    ax.axis('off')\n",
    "\n",
    "# Plot two (8xNimg grid on the right side)\n",
    "axs = np.empty((Nchannel, Nimg), dtype=object)\n",
    "for i in range(Nchannel):\n",
    "    if i < 6:\n",
    "        ichannel = i\n",
    "    else:\n",
    "        ichannel = -(Nchannel - i)\n",
    "    for j in range(Nimg):\n",
    "        axs[i, j] = fig.add_subplot(gs[i, j + 4])\n",
    "        # ax = axs[i, j + 4]  # Offset by 4 columns to place it on the right side\n",
    "        axs[i, j].imshow(img_train[fv_isort_top8[j, isort[ichannel]]].cpu().numpy().squeeze() * ineuron_mask_up, cmap='gray', vmin=-1, vmax=1)\n",
    "        axs[i, j].axis('off')\n",
    "    wc_value = valid_wc[isort[ichannel]]\n",
    "    # Determine the frame color and linewidth based on valid_wc[isort[ichannel]]\n",
    "    if wc_value > 0:\n",
    "        color = 'red'\n",
    "    else:\n",
    "        color = 'blue'\n",
    "    add_channel_frame(axs, i, 0, Nimg - 1, color, np.abs(valid_wc[isort[ichannel]]/np.max(np.abs(valid_wc))))\n",
    "\n",
    "    ax = axs[i, Nimg - 1]  # Rightmost axis in the row\n",
    "    if ichannel < 0: ichannel = len(valid_wc) + ichannel\n",
    "    ax.text(1.1, 0.5, f'channel {ichannel+1}', transform=ax.transAxes,\n",
    "            verticalalignment='center', fontsize=16, color='black', alpha=0.8)\n",
    "plt.suptitle(f'neuron {ineur[0]}, FEVE={test_feve[0]:.3f}', fontsize=26)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
