{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data_path = './data'\n",
    "weight_path = './checkpoints'\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ineuron = 85\n",
    "\n",
    "# load data\n",
    "dat = np.load(os.path.join(data_path, 'monkeyv1_cadena_2019.npz'))\n",
    "images = dat['images']\n",
    "responses = dat['responses'][:, ineuron][:, None]\n",
    "real_responses = dat['real_responses'][:, ineuron][:, None]\n",
    "test_images = dat['test_images']\n",
    "test_responses = dat['test_responses'][:, :, ineuron][:, :, None]\n",
    "test_real_responses = dat['test_real_responses'][:, :, ineuron][:, :, None]\n",
    "train_idx = dat['train_idx']\n",
    "val_idx = dat['val_idx']\n",
    "repetitions = [dat['repetitions'][ineuron]]\n",
    "monkey_id = dat['subject_id']\n",
    "image_ids = dat['image_ids']\n",
    "\n",
    "# normalize responses\n",
    "responses_nan = np.where(real_responses, responses, np.nan)\n",
    "resp_std = np.nanstd(responses_nan)\n",
    "responses = responses / resp_std\n",
    "test_responses = test_responses / resp_std\n",
    "    \n",
    "train_images = images[train_idx]\n",
    "val_images = images[val_idx]\n",
    "train_responses = responses[train_idx]\n",
    "val_responses = responses[val_idx]\n",
    "train_real_responses = real_responses[train_idx]\n",
    "val_real_responses = real_responses[val_idx]\n",
    "\n",
    "print('train:', train_images.shape, train_responses.shape, train_real_responses.shape)\n",
    "print('val:', val_images.shape, val_responses.shape, val_real_responses.shape)\n",
    "print('test:', test_images.shape, test_responses.shape, test_real_responses.shape)\n",
    "\n",
    "print('resp:', responses.min(), responses.max())\n",
    "print('test resp:', test_responses.min(), test_responses.max())\n",
    "\n",
    "test_responses = np.where(test_real_responses, test_responses, np.nan)\n",
    "\n",
    "NN = train_responses.shape[1]\n",
    "Lx, Ly = train_images.shape[2], train_images.shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = torch.from_numpy(train_images)\n",
    "val_images = torch.from_numpy(val_images)\n",
    "train_responses = torch.from_numpy(train_responses)\n",
    "val_responses = torch.from_numpy(val_responses)\n",
    "train_real_responses = torch.from_numpy(train_real_responses)\n",
    "val_real_responses = torch.from_numpy(val_real_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "from minimodel import model_builder\n",
    "seed = 1\n",
    "nlayers = 2\n",
    "nconv1 = 16\n",
    "nconv2 = 64\n",
    "wc_coef = 0.2\n",
    "hs_readout = 0.004\n",
    "l2_readout = 0.2\n",
    "model, in_channels = model_builder.build_model(NN=1, n_layers=nlayers, n_conv=nconv1, n_conv_mid=nconv2, input_Lx=Lx, input_Ly=Ly, Wc_coef=wc_coef)\n",
    "model_name = model_builder.create_model_name('monkeyV1', '2019', ineuron=ineuron, n_layers=nlayers, in_channels=in_channels, seed=seed, hs_readout=hs_readout)\n",
    "model_path = os.path.join(weight_path, 'minimodel', model_name)\n",
    "print('model path: ', model_path)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(model_path):\n",
    "    # initialize model conv1\n",
    "    pretrained_model_path = os.path.join(weight_path, 'fullmodel', 'monkeyV1_2019_2layer_16_320_clamp_norm_depthsep_pool.pt')\n",
    "    pretrained_state_dict = torch.load(pretrained_model_path, map_location=device)\n",
    "    model.core.features.layer0.conv.weight.data = pretrained_state_dict['core.features.layer0.conv.weight']\n",
    "    # set the weight fix\n",
    "    model.core.features.layer0.conv.weight.requires_grad = False\n",
    "\n",
    "    from minimodel import model_trainer\n",
    "    best_state_dict = model_trainer.monkey_train(model, train_responses, train_real_responses, val_responses, val_real_responses, train_images, \\\n",
    "                                                    val_images, device=device, hs_readout=hs_readout, l2_readout=l2_readout)\n",
    "    torch.save(best_state_dict, model_path)\n",
    "    print('model saved', model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(model_path))\n",
    "print('loaded model', model_path)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minimodel import model_trainer\n",
    "test_images = torch.from_numpy(test_images).to(device)\n",
    "spks_pred_test = model_trainer.test_epoch(model, test_images)\n",
    "print('predctions:', spks_pred_test.shape, spks_pred_test.min(), spks_pred_test.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minimodel import metrics\n",
    "test_fev, test_feve = metrics.monkey_feve(test_responses, spks_pred_test, repetitions)\n",
    "print('FEVE (test):', np.mean(test_feve))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check Wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wc = model.readout.Wc.detach().cpu().numpy().squeeze()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3,3))\n",
    "ax.plot(np.sort(Wc))\n",
    "ax.set_title('Wc')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check fullmodel performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minimodel import model_builder\n",
    "seed = 1\n",
    "nlayers = 2\n",
    "nconv1 = 16\n",
    "nconv2 = 320\n",
    "fullmodel, in_channels = model_builder.build_model(NN=166, n_layers=nlayers, n_conv=nconv1, n_conv_mid=nconv2, input_Lx=Lx, input_Ly=Ly)\n",
    "model_name = model_builder.create_model_name('monkeyV1', '2019', n_layers=nlayers, in_channels=in_channels)\n",
    "model_path = os.path.join(weight_path, 'fullmodel', model_name)\n",
    "print('model path: ', model_path)\n",
    "\n",
    "fullmodel.load_state_dict(torch.load(model_path))\n",
    "print('loaded model', model_path)\n",
    "fullmodel = fullmodel.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minimodel import model_trainer\n",
    "# test_images = torch.from_numpy(test_images).to(device)\n",
    "spks_pred_test = model_trainer.test_epoch(fullmodel, test_images)\n",
    "print('predctions:', spks_pred_test.shape, spks_pred_test.min(), spks_pred_test.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minimodel import metrics\n",
    "nstim = spks_pred_test.shape[0]\n",
    "test_fev, test_feve = metrics.monkey_feve(test_responses, spks_pred_test[:, ineuron].reshape((nstim, 1)), repetitions)\n",
    "print('FEVE (test):', np.mean(test_feve))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# category variance (FECV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load txt16 data\n",
    "from minimodel import data\n",
    "fname = 'text16_%s_%s.npz'%(data.db[3]['mname'], data.db[3]['datexp'])\n",
    "dat = np.load(os.path.join(data_path, fname), allow_pickle=True)\n",
    "txt16_spks_test = dat['ss_all']\n",
    "nstim, nrep, nneuron = txt16_spks_test.shape\n",
    "txt16_istim_test = dat['ss_istim'].astype(int)\n",
    "txt16_istim_test = np.repeat(txt16_istim_test[:, np.newaxis], nrep, axis=1).flatten()\n",
    "txt16_labels_test = dat['ss_labels']\n",
    "txt16_labels_test = np.repeat(txt16_labels_test[:, np.newaxis], nrep, axis=1).flatten()\n",
    "\n",
    "print('txt16_labels_test shape:', txt16_labels_test.shape)\n",
    "\n",
    "txt16_istim_train = dat['istim'].astype(int)\n",
    "txt16_labels_train = dat['labels']\n",
    "\n",
    "print('txt16_labels_train shape:', txt16_labels_train.shape)\n",
    "\n",
    "txt16_labels = np.hstack((txt16_labels_train, txt16_labels_test))\n",
    "txt16_istim = np.hstack((txt16_istim_train, txt16_istim_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load txt16 images\n",
    "img = data.load_images(data_path, 3, file=os.path.join(data_path, 'nat60k_text16.mat'), normalize=False)\n",
    "txt16_img = img[txt16_istim]\n",
    "\n",
    "# resize all images to 80x80\n",
    "txt16_img = img[txt16_istim]\n",
    "xrange = np.arange(22, 22+66)\n",
    "txt16_img = txt16_img[:, :, xrange]\n",
    "print(txt16_img.shape, txt16_img.max(), txt16_img.min())\n",
    "\n",
    "import cv2\n",
    "txt16_img = np.array([cv2.resize(img, (80, 80)) for img in txt16_img])\n",
    "print(txt16_img.shape, txt16_img.max(), txt16_img.min())\n",
    "\n",
    "# zscore txt16_imgs\n",
    "img_mean = txt16_img.mean()\n",
    "img_std = txt16_img.std()\n",
    "txt16_img_zscore = (txt16_img - img_mean) / img_std\n",
    "txt16_img_zscore = torch.from_numpy(txt16_img_zscore).to(device).unsqueeze(1)\n",
    "print(txt16_img_zscore.shape)\n",
    "\n",
    "txt16_pred = model_trainer.test_epoch(model, txt16_img_zscore)\n",
    "print('test pred:', txt16_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catvar = metrics.fecv_pairwise(txt16_pred.T, txt16_labels)\n",
    "print(f'FECV (neuron {ineuron}): {catvar[0]:.3f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualize neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the unique train images\n",
    "train_image_ids = image_ids[train_idx]\n",
    "unique_idxes = np.unique(train_image_ids).astype(np.int64)\n",
    "img_train = train_images[unique_idxes].to(device)\n",
    "Nimgs_unique = img_train.shape[0]\n",
    "\n",
    "# get conv2 features of train images (in batches)\n",
    "model.eval()\n",
    "batch_size = 160\n",
    "nconv2 = 64\n",
    "conv2_fvs = np.zeros((Nimgs_unique, nconv2))\n",
    "for i in range(0, Nimgs_unique, batch_size):\n",
    "    images = img_train[i:i+batch_size].to(device)\n",
    "    conv2_fv = model.core(images)\n",
    "    wxy_fv = torch.einsum('iry, irx, ncyx -> ncr', model.readout.Wy, model.readout.Wx, conv2_fv).detach().cpu().numpy().squeeze()\n",
    "    conv2_fvs[i:i+batch_size] = wxy_fv\n",
    "\n",
    "# sort the features and select top 8 image for each channel\n",
    "fv_isort = np.argsort(-conv2_fvs, axis=0)\n",
    "Wc = model.readout.Wc.detach().cpu().numpy().squeeze()\n",
    "ivalid_Wc = np.where(np.abs(Wc)>0.01)[0]\n",
    "print('ivalid_Wc:', len(ivalid_Wc))\n",
    "fv_isort = fv_isort[:, ivalid_Wc]\n",
    "fv_isort_top8 = fv_isort[:8]\n",
    "Nimg, Nchannel = fv_isort_top8.shape\n",
    "\n",
    "# get mask of the images\n",
    "from minimodel.utils import get_image_mask\n",
    "ineuron_mask_up = get_image_mask(model, Ly=Ly, Lx=Lx)\n",
    "\n",
    "# get predictions from the training set\n",
    "neuron_activity_model = model_trainer.test_epoch(model, img_train)\n",
    "neuron_activity_model = neuron_activity_model.squeeze()\n",
    "prediction_isort = np.argsort(neuron_activity_model)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.family'] = 'Arial'\n",
    "# Function to add a frame around a channel\n",
    "def add_channel_frame(axs, row, col_start, col_end, color, alpha, monkey=False):\n",
    "    ax = axs[row, col_start]  # Leftmost axis in the row\n",
    "    if monkey: adjust_value = 1.64\n",
    "    else: adjust_value = 1.33\n",
    "    # Rectangle coordinates (x, y) and dimensions (width, height)\n",
    "    rect = patches.Rectangle(\n",
    "        (-0.025, -0.05), (col_end - col_start + 1)*adjust_value , 1.1, transform=ax.transAxes,\n",
    "        color=color, fill=False, linewidth=3, zorder=10, alpha=alpha,\n",
    "        clip_on=False  # To ensure it draws outside the axes\n",
    "    )\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "\n",
    "# Parameters for the second plot\n",
    "pad = 5\n",
    "vmin = 0\n",
    "vmax = 255\n",
    "valid_wc = Wc[ivalid_Wc]\n",
    "isort = np.argsort(valid_wc)[::-1]\n",
    "Nchannel = np.min([len(valid_wc), 8])\n",
    "\n",
    "# Combined plot layout\n",
    "fig = plt.figure(figsize=(Nimg + 15, 8 * 1.1))\n",
    "gs = plt.GridSpec(8, Nimg + 4, figure=fig, hspace=0.3, wspace=0.1, width_ratios=[1, 1, 1, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5])\n",
    "\n",
    "# Plot one (4x4 grid on the left side, occupying 2 rows per row)\n",
    "nshow = 16\n",
    "for i in range(nshow):\n",
    "    row = (i // 4) * 2\n",
    "    col = i % 4\n",
    "    ax = fig.add_subplot(gs[row:row + 2, col])\n",
    "    ax.imshow(img_train[prediction_isort[i]].cpu().numpy().squeeze() * ineuron_mask_up, cmap='gray', vmin=-1, vmax=1)\n",
    "    ax.axis('off')\n",
    "\n",
    "# Plot two (8xNimg grid on the right side)\n",
    "axs = np.empty((8, Nimg), dtype=object)\n",
    "for i in range(Nchannel):\n",
    "    if i < 6:\n",
    "        ichannel = i\n",
    "    else:\n",
    "        ichannel = -(Nchannel - i)\n",
    "    for j in range(Nimg):\n",
    "        axs[i, j] = fig.add_subplot(gs[i, j + 4])\n",
    "        axs[i, j].imshow(img_train[fv_isort_top8[j, isort[ichannel]]].cpu().numpy().squeeze() * ineuron_mask_up, cmap='gray', vmin=-1, vmax=1)\n",
    "        axs[i, j].axis('off')\n",
    "    wc_value = valid_wc[isort[ichannel]]\n",
    "    # Determine the frame color and linewidth based on valid_wc[isort[ichannel]]\n",
    "    if wc_value > 0:\n",
    "        color = 'red'\n",
    "    else:\n",
    "        color = 'blue'\n",
    "    add_channel_frame(axs, i, 0, Nimg - 1, color, np.abs(valid_wc[isort[ichannel]]/np.max(np.abs(valid_wc))), monkey=True)\n",
    "\n",
    "    ax = axs[i, Nimg - 1]  # Rightmost axis in the row\n",
    "    if ichannel < 0: ichannel = len(valid_wc) + ichannel\n",
    "    ax.text(1.2, 0.5, f'channel {ichannel+1}', transform=ax.transAxes,\n",
    "            verticalalignment='center', fontsize=16, color='black', alpha=0.8)\n",
    "plt.suptitle(f'neuron {ineuron}, FEVE={test_feve[0]:.3f}, FECV={catvar[0]:.3f}', fontsize=18)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
