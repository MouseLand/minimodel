{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minimodel import data\n",
    "mouse_id = 4\n",
    "\n",
    "data_path = './data'\n",
    "weight_path = './checkpoints'\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images\n",
    "img = data.load_images(data_path, mouse_id, file=data.img_file_name[mouse_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load neurons\n",
    "fname = '%s_nat60k_%s.npz'%(data.db[mouse_id]['mname'], data.db[mouse_id]['datexp'])\n",
    "spks, istim_train, istim_test, xpos, ypos, spks_rep_all = data.load_neurons(file_path = os.path.join(data_path, fname), mouse_id = mouse_id)\n",
    "n_stim, n_neurons = spks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and validation set\n",
    "itrain, ival = data.split_train_val(istim_train, train_frac=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spks, spks_rep_all = data.normalize_spks(spks, spks_rep_all, itrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ineuron = 3218\n",
    "ineur = [ineuron]\n",
    "spks_train = torch.from_numpy(spks[itrain][:,ineur])\n",
    "spks_val = torch.from_numpy(spks[ival][:,ineur]) \n",
    "print('spks_train: ', spks_train.shape, spks_train.min(), spks_train.max())\n",
    "print('spks_val: ', spks_val.shape, spks_val.min(), spks_val.max())\n",
    "\n",
    "img_train = torch.from_numpy(img[istim_train][itrain]).to(device).unsqueeze(1) # change :130 to 25:100 \n",
    "img_val = torch.from_numpy(img[istim_train][ival]).to(device).unsqueeze(1)\n",
    "img_test = torch.from_numpy(img[istim_test]).to(device).unsqueeze(1)\n",
    "\n",
    "print('img_train: ', img_train.shape, img_train.min(), img_train.max())\n",
    "print('img_val: ', img_val.shape, img_val.min(), img_val.max())\n",
    "print('img_test: ', img_test.shape, img_test.min(), img_test.max())\n",
    "\n",
    "input_Ly, input_Lx = img_train.shape[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "from minimodel import model_builder\n",
    "nlayers = 2\n",
    "nconv1 = 16\n",
    "nconv2 = 64\n",
    "seed = 1\n",
    "hs_readout = 0.03\n",
    "wc_coef = 0.2\n",
    "model, in_channels = model_builder.build_model(NN=1, n_layers=nlayers, n_conv=nconv1, n_conv_mid=nconv2, Wc_coef=wc_coef)\n",
    "model_name = model_builder.create_model_name(data.mouse_names[mouse_id], data.exp_date[mouse_id], ineuron=ineur[0], n_layers=nlayers, in_channels=in_channels, seed=seed,hs_readout=hs_readout)\n",
    "\n",
    "model_path = os.path.join(weight_path, model_name)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "from minimodel import model_trainer\n",
    "if not os.path.exists(model_path):\n",
    "    if mouse_id == 5: pretrained_model_path = os.path.join(weight_path, f'{data.mouse_names[mouse_id]}_{data.exp_date[mouse_id]}_2layer_16_320_clamp_norm_depthsep_pool_xrange_176.pt')\n",
    "    else: pretrained_model_path = os.path.join(weight_path, f'{data.mouse_names[mouse_id]}_{data.exp_date[mouse_id]}_2layer_16_320_clamp_norm_depthsep_pool.pt')\n",
    "    print('pretrained_model_path: ', pretrained_model_path)\n",
    "    pretrained_state_dict = torch.load(pretrained_model_path, map_location=device)\n",
    "    # initialize conv1 with the fullmodel weights\n",
    "    model.core.features.layer0.conv.weight.data = pretrained_state_dict['core.features.layer0.conv.weight']\n",
    "    model.core.features.layer0.conv.weight.requires_grad = False\n",
    "    best_state_dict = model_trainer.train(model, spks_train, spks_val, img_train, img_val, device=device, l2_readout=0.2, hs_readout=hs_readout)\n",
    "    torch.save(best_state_dict, model_path)\n",
    "    print('saved model', model_path)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "print('loaded model', model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model\n",
    "test_pred = model_trainer.test_epoch(model, img_test)\n",
    "print('test_pred: ', test_pred.shape, test_pred.min(), test_pred.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minimodel import metrics\n",
    "spks_rep = []\n",
    "for i in range(len(spks_rep_all)):\n",
    "    spks_rep.append(spks_rep_all[i][:,ineur])\n",
    "test_fev, test_feve = metrics.feve(spks_rep, test_pred)\n",
    "# print('FEV (test): ', np.mean(test_fev))\n",
    "print('FEVE (test): ', np.mean(test_feve))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check Wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wc = model.readout.Wc.detach().cpu().numpy().squeeze()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3,3))\n",
    "ax.plot(np.sort(Wc))\n",
    "ax.set_title('Wc')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check fullmodel performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minimodel import model_builder\n",
    "nlayers = 2\n",
    "nconv1 = 16\n",
    "nconv2 = 320\n",
    "fullmodel, in_channels = model_builder.build_model(NN=n_neurons, n_layers=nlayers, n_conv=nconv1, n_conv_mid=nconv2)\n",
    "model_name = model_builder.create_model_name(data.mouse_names[mouse_id], data.exp_date[mouse_id], n_layers=nlayers, in_channels=in_channels)\n",
    "model_path = os.path.join(weight_path, model_name)\n",
    "\n",
    "fullmodel.load_state_dict(torch.load(model_path))\n",
    "print('loaded model', model_path)\n",
    "fullmodel = fullmodel.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model_trainer.test_epoch(fullmodel, img_test)\n",
    "print('test_pred: ', test_pred.shape, test_pred.min(), test_pred.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minimodel import metrics\n",
    "test_fev, test_feve = metrics.feve(spks_rep, test_pred[:, ineur])\n",
    "print('FEVE (test): ', np.mean(test_feve))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate category variance (FECV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load txt16 data\n",
    "fname = 'text16_%s_%s.npz'%(data.db[mouse_id]['mname'], data.db[mouse_id]['datexp'])\n",
    "dat = np.load(os.path.join(data_path, fname), allow_pickle=True)\n",
    "txt16_spks_test = dat['ss_all']\n",
    "nstim, nrep, nneuron = txt16_spks_test.shape\n",
    "txt16_istim_test = dat['ss_istim'].astype(int)\n",
    "txt16_istim_test = np.repeat(txt16_istim_test[:, np.newaxis], nrep, axis=1).flatten()\n",
    "txt16_labels_test = dat['ss_labels']\n",
    "txt16_labels_test = np.repeat(txt16_labels_test[:, np.newaxis], nrep, axis=1).flatten()\n",
    "\n",
    "print('txt16_labels_test shape:', txt16_labels_test.shape)\n",
    "\n",
    "txt16_istim_train = dat['istim'].astype(int)\n",
    "txt16_labels_train = dat['labels']\n",
    "\n",
    "print('txt16_labels_train shape:', txt16_labels_train.shape)\n",
    "\n",
    "txt16_labels = np.hstack((txt16_labels_train, txt16_labels_test))\n",
    "txt16_istim = np.hstack((txt16_istim_train, txt16_istim_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load txt16 images\n",
    "img = data.load_images(data_path, mouse_id, file='nat60k_text16.mat', normalize=False)\n",
    "txt16_img = img[txt16_istim]\n",
    "# zscore txt16_imgs\n",
    "img_mean = txt16_img.mean()\n",
    "img_std = txt16_img.std()\n",
    "txt16_img_zscore = (txt16_img - img_mean) / img_std\n",
    "txt16_img_zscore = torch.from_numpy(txt16_img_zscore).to(device).unsqueeze(1)\n",
    "print(txt16_img_zscore.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt16_pred = model_trainer.test_epoch(model, txt16_img_zscore)\n",
    "print('test pred:', txt16_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catvar = metrics.fecv_pairwise(txt16_pred.T, txt16_labels)\n",
    "print(f'FECV (neuron {ineur[0]}): {catvar[0]:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualize neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the unique train images\n",
    "Nimgs_unique = img_train.shape[0]\n",
    "\n",
    "# get conv2 features of train images (in batches)\n",
    "model.eval()\n",
    "batch_size = 160\n",
    "nconv2 = 64\n",
    "conv2_fvs = np.zeros((Nimgs_unique, nconv2))\n",
    "for i in range(0, Nimgs_unique, batch_size):\n",
    "    images = img_train[i:i+batch_size].to(device)\n",
    "    conv2_fv = model.core(images)\n",
    "    wxy_fv = torch.einsum('iry, irx, ncyx -> ncr', model.readout.Wy, model.readout.Wx, conv2_fv).detach().cpu().numpy().squeeze()\n",
    "    conv2_fvs[i:i+batch_size] = wxy_fv\n",
    "\n",
    "# sort the features and select top 8 image for each channel\n",
    "fv_isort = np.argsort(-conv2_fvs, axis=0)\n",
    "Wc = model.readout.Wc.detach().cpu().numpy().squeeze()\n",
    "ivalid_Wc = np.where(np.abs(Wc)>0.01)[0]\n",
    "print('ivalid_Wc:', len(ivalid_Wc))\n",
    "fv_isort = fv_isort[:, ivalid_Wc]\n",
    "fv_isort_top8 = fv_isort[:8]\n",
    "Nimg, Nchannel = fv_isort_top8.shape\n",
    "\n",
    "# get mask of the images\n",
    "from minimodel.utils import get_image_mask\n",
    "ineuron_mask_up = get_image_mask(model, Ly=input_Ly, Lx=input_Lx)\n",
    "\n",
    "# get predictions from the training set\n",
    "neuron_activity_model = model_trainer.test_epoch(model, img_train)\n",
    "neuron_activity_model = neuron_activity_model.squeeze()\n",
    "prediction_isort = np.argsort(neuron_activity_model)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from minimodel.utils import add_channel_frame\n",
    "\n",
    "# Parameters for the second plot\n",
    "pad = 5\n",
    "vmin = 0\n",
    "vmax = 255\n",
    "valid_wc = Wc[ivalid_Wc]\n",
    "isort = np.argsort(valid_wc)[::-1]\n",
    "Nchannel = 8\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.family'] = 'Arial'\n",
    "# Combined plot layout\n",
    "fig = plt.figure(figsize=(Nimg * 2 + 20, Nchannel * 1.1))\n",
    "gs = plt.GridSpec(Nchannel, Nimg + 4, figure=fig, hspace=0.3, wspace=0.1, width_ratios=[1, 1, 1, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5])\n",
    "\n",
    "# Plot one (4x4 grid on the left side, occupying 2 rows per row)\n",
    "nshow = 16\n",
    "for i in range(nshow):\n",
    "    row = (i // 4) * 2\n",
    "    col = i % 4\n",
    "    ax = fig.add_subplot(gs[row:row + 2, col])\n",
    "    ax.imshow(img_train[prediction_isort[i]].cpu().numpy().squeeze() * ineuron_mask_up, cmap='gray', vmin=-1, vmax=1)\n",
    "    ax.axis('off')\n",
    "\n",
    "# Plot two (8xNimg grid on the right side)\n",
    "axs = np.empty((Nchannel, Nimg), dtype=object)\n",
    "for i in range(Nchannel):\n",
    "    if i < 6:\n",
    "        ichannel = i\n",
    "    else:\n",
    "        ichannel = -(Nchannel - i)\n",
    "    for j in range(Nimg):\n",
    "        axs[i, j] = fig.add_subplot(gs[i, j + 4])\n",
    "        # ax = axs[i, j + 4]  # Offset by 4 columns to place it on the right side\n",
    "        axs[i, j].imshow(img_train[fv_isort_top8[j, isort[ichannel]]].cpu().numpy().squeeze() * ineuron_mask_up, cmap='gray', vmin=-1, vmax=1)\n",
    "        axs[i, j].axis('off')\n",
    "    wc_value = valid_wc[isort[ichannel]]\n",
    "    # Determine the frame color and linewidth based on valid_wc[isort[ichannel]]\n",
    "    if wc_value > 0:\n",
    "        color = 'red'\n",
    "    else:\n",
    "        color = 'blue'\n",
    "    add_channel_frame(axs, i, 0, Nimg - 1, color, np.abs(valid_wc[isort[ichannel]]/np.max(np.abs(valid_wc))))\n",
    "\n",
    "    ax = axs[i, Nimg - 1]  # Rightmost axis in the row\n",
    "    if ichannel < 0: ichannel = len(valid_wc) + ichannel\n",
    "    ax.text(1.1, 0.5, f'channel {ichannel+1}', transform=ax.transAxes,\n",
    "            verticalalignment='center', fontsize=16, color='black', alpha=0.8)\n",
    "plt.suptitle(f'neuron {ineur[0]}, FEVE={test_feve[0]:.3f}, FECV={catvar[0]:.3f}', fontsize=18)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
