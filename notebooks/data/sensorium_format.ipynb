{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from minimodel import data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load image and neural data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "mouse_id = 5\n",
    "\n",
    "# load images\n",
    "data_path = './'\n",
    "img = data.load_images(data_path, mouse_id, file=os.path.join(data_path, data.img_file_name[mouse_id]), normalize=False)\n",
    "print('img: ', img.shape, img.min(), img.max(), img.dtype)\n",
    "\n",
    "# load neurons\n",
    "fname = '%s_nat60k_%s.npz'%(data.db[mouse_id]['mname'], data.db[mouse_id]['datexp'])\n",
    "spks, istim_train, istim_test, xpos, ypos, spks_rep_all = data.load_neurons(file_path = os.path.join(data_path, fname), mouse_id = mouse_id)\n",
    "n_stim, n_max_neurons = spks.shape\n",
    "\n",
    "# split train and validation set\n",
    "itrain, ival = data.split_train_val(istim_train, train_frac=0.9)\n",
    "\n",
    "ineur = np.arange(0, n_max_neurons)\n",
    "spks_train = spks[itrain][:,ineur]\n",
    "spks_val = spks[ival][:,ineur]\n",
    "\n",
    "print('spks_train: ', spks_train.shape, spks_train.min(), spks_train.max())\n",
    "print('spks_val: ', spks_val.shape, spks_val.min(), spks_val.max())\n",
    "\n",
    "img_train = img[istim_train][itrain]\n",
    "img_val = img[istim_train][ival]\n",
    "img_test = img[istim_test]\n",
    "\n",
    "print('img_train: ', img_train.shape, img_train.min(), img_train.max())\n",
    "print('img_val: ', img_val.shape, img_val.min(), img_val.max())\n",
    "print('img_test: ', img_test.shape, img_test.min(), img_test.max())\n",
    "\n",
    "input_Ly, input_Lx = img_train.shape[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store reshaped spks_test and img_test\n",
    "spks_test_list = []\n",
    "img_test_list = []\n",
    "image_id_test_list = []\n",
    "\n",
    "# Iterate over each stimulus in the test set\n",
    "for i, spks in enumerate(spks_rep_all):\n",
    "    nrep, nneurons = spks.shape\n",
    "    spks_test_list.append(spks)\n",
    "    \n",
    "    # Reshape the corresponding img_test\n",
    "    img_rep = img_test[i][None, :, :].repeat(nrep, axis=0)\n",
    "    img_test_list.append(img_rep)\n",
    "    \n",
    "    # Repeat the image ID for each repeat\n",
    "    image_id_test_list.append(np.repeat(istim_test[i], nrep))\n",
    "\n",
    "# Concatenate the reshaped test data\n",
    "spks_test = np.concatenate(spks_test_list, axis=0)\n",
    "img_test = np.concatenate(img_test_list, axis=0)\n",
    "image_id_test = np.concatenate(image_id_test_list, axis=0)\n",
    "\n",
    "print('spks_test: ', spks_test.shape, spks_test.min(), spks_test.max())\n",
    "print('img_test: ', img_test.shape, img_test.min(), img_test.max())\n",
    "print('image_id_test: ', image_id_test.shape, image_id_test.min(), image_id_test.max())\n",
    "\n",
    "# Concatenate train, val, and test sets\n",
    "spk_all = np.concatenate([spks_train, spks_val, spks_test], axis=0)\n",
    "img_all = np.concatenate([img_train, img_val, img_test], axis=0)\n",
    "image_id_all = np.concatenate([istim_train[itrain], istim_train[ival], image_id_test], axis=0)\n",
    "\n",
    "ntrain, nval = len(spks_train), len(spks_val)\n",
    "ntest = len(spks_test)\n",
    "itrain = np.arange(ntrain)\n",
    "ival = np.arange(ntrain, ntrain + nval)\n",
    "itest = np.arange(ntrain + nval, ntrain + nval + ntest)\n",
    "\n",
    "print('spks_all: ', spk_all.shape, spk_all.min(), spk_all.max())\n",
    "print('img_all: ', img_all.shape, img_all.min(), img_all.max())\n",
    "print('image_id_all: ', image_id_all.shape, image_id_all.min(), image_id_all.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save image and neural data\n",
    "print(spk_all.shape, img_all.shape)\n",
    "NT, NN = spk_all.shape\n",
    "data_path = f'./nat30k_{data.mouse_names[mouse_id]}_{data.exp_date[mouse_id]}'\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "# set up data folder\n",
    "img_path = os.path.join(data_path, 'data/images')\n",
    "spk_path = os.path.join(data_path, 'data/responses')\n",
    "os.makedirs(img_path, exist_ok=True)\n",
    "os.makedirs(spk_path, exist_ok=True)\n",
    "\n",
    "for i in range(img_all.shape[0]):\n",
    "    img_savepath = os.path.join(img_path, f'{i}.npy')\n",
    "    spk_savepath = os.path.join(spk_path, f'{i}.npy')\n",
    "    timg = img_all[i]\n",
    "    np.save(img_savepath, timg[np.newaxis, ...])\n",
    "    np.save(spk_savepath, spk_all[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup meta folder\n",
    "# setup meta/statistics folder\n",
    "img_stats = [img_all.max(), img_all.min(), img_all.mean(), np.median(img[:]), img.std()]\n",
    "img_stats_folder = os.path.join(data_path, 'meta', 'statistics', 'images')\n",
    "os.makedirs(img_stats_folder, exist_ok=True)\n",
    "\n",
    "X_stats = [spk_all.max(axis=0), spk_all.min(axis=0), spk_all.mean(axis=0), np.median(spk_all, axis=0), spk_all.std(axis=0)]\n",
    "X_stats_folder = os.path.join(data_path, 'meta', 'statistics', 'responses')\n",
    "os.makedirs(X_stats_folder, exist_ok=True)\n",
    "\n",
    "stats_names = ['max', 'min', 'mean', 'median', 'std']\n",
    "\n",
    "for folder in ['all', 'stimulus_frame']:\n",
    "    Xs_folder = os.path.join(X_stats_folder, folder)\n",
    "    os.makedirs(Xs_folder, exist_ok=True)\n",
    "    imgs_folder = os.path.join(img_stats_folder, folder)\n",
    "    os.makedirs(imgs_folder, exist_ok=True)\n",
    "    for istat, xstat, sname in zip(img_stats, X_stats, stats_names):\n",
    "        np.save(os.path.join(Xs_folder, f'{sname}.npy'), xstat)\n",
    "        np.save(os.path.join(imgs_folder, f'{sname}.npy'), istat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup meta/trials folder\n",
    "# save tiers.npy\n",
    "meta_trials_folder = os.path.join(data_path, 'meta', 'trials')\n",
    "os.makedirs(meta_trials_folder, exist_ok=True)\n",
    "tier_path = os.path.join(meta_trials_folder, 'tiers.npy')\n",
    "\n",
    "tiers = np.zeros(NT, object)\n",
    "tiers[itrain] = 'train'\n",
    "tiers[ival] = 'validation'\n",
    "tiers[itest] = 'test'\n",
    "tiers = np.array(list(tiers))\n",
    "np.save(tier_path, tiers)\n",
    "\n",
    "# save frame_image_id.npy\n",
    "frame_image_id_path = os.path.join(meta_trials_folder, 'frame_image_id.npy')\n",
    "np.save(frame_image_id_path, image_id_all)\n",
    "\n",
    "# save trial_idx.npy\n",
    "trial_idx_path = os.path.join(meta_trials_folder, 'trial_idx.npy')\n",
    "trial_idx = np.arange(NT)\n",
    "np.save(trial_idx_path, trial_idx)\n",
    "\n",
    "# save frame_image_class.npy\n",
    "image_class_path = os.path.join(meta_trials_folder, 'frame_image_class.npy')\n",
    "image_class = np.zeros(NT)\n",
    "np.save(image_class_path, image_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta/neurons folder\n",
    "meta_neurons_folder = os.path.join(data_path, 'meta', 'neurons')\n",
    "os.makedirs(meta_neurons_folder, exist_ok=True)\n",
    "# sen_meta_neurons_folder = os.path.join(sen_data_path, 'meta', 'neurons')\n",
    "# NN_sen = len(np.load(os.path.join(sen_meta_neurons_folder, 'layer.npy')))\n",
    "\n",
    "# save cell_motor_coordinates.npy\n",
    "coordinates_path = os.path.join(meta_neurons_folder, 'cell_motor_coordinates.npy')\n",
    "data = np.zeros((NN, 3))\n",
    "data[:, 0] = xpos\n",
    "data[:, 1] = ypos\n",
    "np.save(coordinates_path, data)\n",
    "\n",
    "# save unit_ids.npy\n",
    "unit_ids_path = os.path.join(meta_neurons_folder, 'unit_ids.npy')\n",
    "unit_ids = np.arange(NN)\n",
    "np.save(unit_ids_path, unit_ids)\n",
    "\n",
    "# save area.npy\n",
    "area_path = os.path.join(meta_neurons_folder, 'area.npy')\n",
    "area = np.array(['V1'] * NN)\n",
    "np.save(area_path, area)\n",
    "\n",
    "# save animal_ids.npy\n",
    "animal_ids_path = os.path.join(meta_neurons_folder, 'animal_ids.npy')\n",
    "animal_ids = np.ones(NN) * mouse_id\n",
    "np.save(animal_ids_path, animal_ids.astype(int))\n",
    "\n",
    "# save sessions.npy\n",
    "session_path = os.path.join(meta_neurons_folder, 'sessions.npy')\n",
    "sessions = np.ones(NT)\n",
    "np.save(session_path, sessions.astype(int))\n",
    "\n",
    "# save scan_idx.npy\n",
    "scan_idx_path = os.path.join(meta_neurons_folder, 'scan_idx.npy')\n",
    "scan_idx = np.ones(NT)\n",
    "np.save(scan_idx_path, scan_idx.astype(int))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the SENSORIUM dataset\n",
    "from nnfabrik.builder import get_data\n",
    "dataset_name = 'nat30k'\n",
    "n_layers = 1\n",
    "filenames = [data_path, ]\n",
    "dataset_fn = 'sensorium.datasets.static_loaders'\n",
    "dataset_config = {'paths': filenames,\n",
    "                 'normalize': True,\n",
    "                 'include_behavior': False,\n",
    "                 'include_eye_position': False,\n",
    "                 'batch_size': 128,\n",
    "                 'scale':1.0,\n",
    "                 'add_behavior_as_channels': False,\n",
    "                 }\n",
    "\n",
    "dataloaders = get_data(dataset_fn, dataset_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tier = 'test'\n",
    "sen_dataset_name = f'{mouse_id}-1-1' # animal_id-session_id-scan_idx\n",
    "\n",
    "images, responses = [], []\n",
    "for x, y in dataloaders[tier][sen_dataset_name]:\n",
    "    images.append(x.squeeze().cpu().data.numpy())\n",
    "    responses.append(y.squeeze().cpu().data.numpy())\n",
    "    \n",
    "images = np.vstack(images)\n",
    "responses = np.vstack(responses)\n",
    "\n",
    "print('The \\\"{}\\\" set of dataset \\\"{}\\\" contains the responses of {} neurons to {} images'.format(tier, dataset_name, responses.shape[1], responses.shape[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "2fb04159266c5104cdf5f50c6f21e7e9d4b45ea8768cbf39b3d3b410a08a5cb6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
