{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from minimodel import data, metrics, model_builder, model_trainer\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "data_dict = {}\n",
    "\n",
    "data_path = '../../data'\n",
    "weight_path = '../checkpoints/fullmodel'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_list = ['conv2_1x1', 'conv2_spatial', 'conv2_relu', 'Wxy', 'elu']\n",
    "catvar_data_path = os.path.join('outputs', 'catvar', 'monkey') # where the catvar files saved\n",
    "nneurons = 166\n",
    "catvar_all = np.zeros((nneurons, len(op_list)))\n",
    "channel_activities_all = np.zeros((nneurons, 12800, 64))\n",
    "wc_all = np.zeros((nneurons, 64))\n",
    "ineurons = np.arange(nneurons)\n",
    "pred_all = np.zeros((nneurons, 12800))\n",
    "for i, ineuron in enumerate(ineurons):\n",
    "    ineur = [ineuron]\n",
    "    file_name = f'monkey_minimodel_16_64_pairwise_catvar_neuron{ineur[0]}_result.npz'\n",
    "    file_path = os.path.join(catvar_data_path, file_name)\n",
    "    dat = np.load(file_path, allow_pickle=True)\n",
    "    channel_activities = dat['channel_activities']\n",
    "    op_names = dat['op_names']\n",
    "    catvar = dat['catvar']\n",
    "    catvar_all[i] = catvar\n",
    "    channel_activities_all[i] = channel_activities\n",
    "    pred_all[i] = dat['pred'].squeeze()\n",
    "\n",
    "    file_path = f'outputs/minimodel_monkey_result.npz'\n",
    "    dat = np.load(file_path, allow_pickle=True)\n",
    "    wc_all[i] = dat['wc_all'][i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlaton of positive channels\n",
    "# Initialize list to store mean correlations for each neuron\n",
    "mean_correlations = []\n",
    "\n",
    "# Loop through each neuron\n",
    "for neuron_idx in range(channel_activities_all.shape[0]):\n",
    "    # Get the weights and channel activities for the current neuron\n",
    "    weights = wc_all[neuron_idx]\n",
    "    activities = channel_activities_all[neuron_idx]\n",
    "    \n",
    "    # Get the indices of channels with positive weights\n",
    "    positive_indices = np.where(weights > 0.01)[0]\n",
    "    \n",
    "    if len(positive_indices) > 1:\n",
    "        # Calculate correlations between channels with positive weights\n",
    "        correlations = []\n",
    "        for i in range(len(positive_indices)):\n",
    "            for j in range(i + 1, len(positive_indices)):\n",
    "                idx1, idx2 = positive_indices[i], positive_indices[j]\n",
    "                corr, _ = pearsonr(activities[:, idx1], activities[:, idx2])\n",
    "                correlations.append(corr)\n",
    "        \n",
    "        # Calculate the mean correlation for the current neuron\n",
    "        mean_correlation = np.mean(correlations)\n",
    "    else:\n",
    "        # If there are less than 2 channels with positive weights, correlation is not defined\n",
    "        mean_correlation = 0\n",
    "    \n",
    "    # Append the mean correlation to the list\n",
    "    mean_correlations.append(mean_correlation)\n",
    "\n",
    "# Convert the list to a numpy array for easier handling\n",
    "mean_correlations = np.array(mean_correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = np.load(f'outputs/minimodel_monkey_result.npz', allow_pickle=True)\n",
    "feve_all = dat['feve_all']\n",
    "test_pred_all = dat['test_pred_all']\n",
    "wc_all = dat['wc_all']\n",
    "nconv2 = np.sum(np.abs(wc_all) > 0.01, axis=1)\n",
    "print(test_pred_all.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conv1 catvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load txt16 data\n",
    "mouse_id = 4\n",
    "fname = 'text16_%s_%s.npz'%(data.db[mouse_id]['mname'], data.db[mouse_id]['datexp'])\n",
    "dat = np.load(os.path.join(data_path, fname), allow_pickle=True)\n",
    "txt16_spks_test = dat['ss_all']\n",
    "nstim, nrep, nneuron = txt16_spks_test.shape\n",
    "txt16_istim_test = dat['ss_istim'].astype(int)\n",
    "txt16_istim_test = np.repeat(txt16_istim_test[:, np.newaxis], nrep, axis=1).flatten()\n",
    "txt16_spks_test = txt16_spks_test.reshape(-1, nneuron)\n",
    "txt16_labels_test = dat['ss_labels']\n",
    "txt16_labels_test = np.repeat(txt16_labels_test[:, np.newaxis], nrep, axis=1).flatten()\n",
    "\n",
    "print('txt16_spks_test shape:', txt16_spks_test.shape)\n",
    "print('txt16_labels_test shape:', txt16_labels_test.shape)\n",
    "\n",
    "\n",
    "txt16_spks_train = dat['sp'].T\n",
    "txt16_istim_train = dat['istim'].astype(int)\n",
    "txt16_labels_train = dat['labels']\n",
    "\n",
    "print('txt16_spks_train shape:', txt16_spks_train.shape)\n",
    "print('txt16_labels_train shape:', txt16_labels_train.shape)\n",
    "\n",
    "txt16_spks = np.vstack((txt16_spks_train, txt16_spks_test))\n",
    "txt16_labels = np.hstack((txt16_labels_train, txt16_labels_test))\n",
    "txt16_istim = np.hstack((txt16_istim_train, txt16_istim_test))\n",
    "\n",
    "print('txt16_spks shape:', txt16_spks.shape)\n",
    "print('txt16_labels shape:', txt16_labels.shape)\n",
    "\n",
    "from scipy.stats import zscore\n",
    "txt16_spks = zscore(txt16_spks, axis=0)\n",
    "pred_catvar = metrics.category_variance_pairwise(pred_all, txt16_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_op_list = ['conv1', 'conv1_relu', 'conv1_pool']\n",
    "\n",
    "# load txt16 images\n",
    "img = data.load_images(data_path, mouse_id, file=os.path.join(data_path, 'nat60k_text16.mat'), normalize=False)\n",
    "# img = data.load_images_mat(img_root, file='nat60k_text16.mat', downsample=1, normalize=True, crop=False, origin=True)[0]\n",
    "print('img: ', img.shape, img.min(), img.max(), img.dtype)\n",
    "\n",
    "txt16_img = img[txt16_istim]\n",
    "print(txt16_img.shape, txt16_img.max(), txt16_img.min())\n",
    "\n",
    "# zscore txt16_imgs\n",
    "img_mean = txt16_img.mean()\n",
    "img_std = txt16_img.std()\n",
    "txt16_img_zscore = (txt16_img - img_mean) / img_std\n",
    "print(txt16_img_zscore.shape, txt16_img_zscore.max(), txt16_img_zscore.min())\n",
    "txt16_img_zscore = torch.from_numpy(txt16_img_zscore).to(device).unsqueeze(1)\n",
    "print(txt16_img_zscore.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "seed = 1\n",
    "nlayers = 2\n",
    "nconv1 = 16\n",
    "nconv2 = 64\n",
    "wc_coef = 0.2\n",
    "hs_readout = 0.003\n",
    "l2_readout = 0.2\n",
    "Lx, Ly = 80, 80\n",
    "model, in_channels = model_builder.build_model(NN=1, n_layers=nlayers, n_conv=nconv1, n_conv_mid=nconv2, input_Lx=Lx, input_Ly=Ly, Wc_coef=wc_coef)\n",
    "model_name = model_builder.create_model_name('monkeyV1', '2019', ineuron=ineuron, n_layers=nlayers, in_channels=in_channels, seed=seed, \n",
    "                                    hs_readout=hs_readout)\n",
    "weight_path = os.path.join(weight_path, 'minimodel', 'monkeyV1')\n",
    "model_path = os.path.join(weight_path, model_name)\n",
    "print('model path: ', model_path)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "print('loaded model', model_path)\n",
    "model = model.to(device)\n",
    "\n",
    "model.eval()\n",
    "conv1_fvs = model.core.features.layer0.conv(txt16_img_zscore)\n",
    "print('after conv1: ', conv1_fvs.shape, conv1_fvs.max(), conv1_fvs.min())\n",
    "conv1_bn_fvs = model.core.features.layer0.norm(conv1_fvs)\n",
    "print('after conv1_bn: ', conv1_bn_fvs.shape, conv1_bn_fvs.max(), conv1_bn_fvs.min())\n",
    "conv1_relu_fvs = model.core.features.layer0.activation(conv1_bn_fvs)\n",
    "print('after conv1_relu: ', conv1_relu_fvs.shape, conv1_relu_fvs.max(), conv1_relu_fvs.min())\n",
    "conv1_pool_fvs = model.core.features.layer0.pool(conv1_relu_fvs)\n",
    "print('after conv1_pool: ', conv1_pool_fvs.shape, conv1_pool_fvs.max(), conv1_pool_fvs.min())\n",
    "\n",
    "conv1_fvs_all = [conv1_fvs.cpu().detach().numpy(), conv1_relu_fvs.cpu().detach().numpy(), conv1_pool_fvs.cpu().detach().numpy()]\n",
    "\n",
    "conv1_catvar_all = np.zeros(len(conv1_op_list))\n",
    "for i in range(len(conv1_op_list)):\n",
    "    fv = conv1_fvs_all[i].reshape(conv1_fvs_all[i].shape[0], -1) # (nstim, nfeatures)\n",
    "    cat_var = metrics.category_variance_pairwise(fv.T, txt16_labels)\n",
    "    conv1_catvar_all[i] = np.nanmean(cat_var)\n",
    "\n",
    "print(conv1_catvar_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nneurons = catvar_all.shape[0]\n",
    "conv1_catvar_all = np.repeat(conv1_catvar_all[np.newaxis, :], nneurons, axis=0)\n",
    "print(conv1_catvar_all.shape, catvar_all.shape)\n",
    "catvar_all = np.hstack([conv1_catvar_all, catvar_all])\n",
    "print(catvar_all.shape)\n",
    "\n",
    "op_list = conv1_op_list + op_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save \n",
    "save_path = './outputs/'\n",
    "fname = f'catvar_monkey_result.npz'\n",
    "fpath = os.path.join(save_path, fname)\n",
    "data_dict = {}\n",
    "data_dict['model_catvar'] = catvar_all\n",
    "data_dict['mean_correlation'] = mean_correlations\n",
    "data_dict['op_names'] = op_list\n",
    "data_dict['wc_all'] = wc_all\n",
    "# data_dict['channel_activities_all'] = channel_activities_all\n",
    "data_dict['pred_catvar'] = pred_catvar\n",
    "np.savez(fpath, **data_dict)\n",
    "print(f'saved to {fpath}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
