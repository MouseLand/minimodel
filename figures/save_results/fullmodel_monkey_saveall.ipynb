{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from minimodel import data, metrics, model_builder, model_trainer\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "data_dict = {}\n",
    "\n",
    "data_path = '../../data'\n",
    "weight_path = '../checkpoints/fullmodel'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n_layers result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "dat = np.load(os.path.join(data_path, 'monkeyv1_cadena_2019.npz'))\n",
    "images = dat['images']\n",
    "responses = dat['responses']\n",
    "real_responses = dat['real_responses']\n",
    "test_images = dat['test_images']\n",
    "test_responses = dat['test_responses']\n",
    "test_real_responses = dat['test_real_responses']\n",
    "train_idx = dat['train_idx']\n",
    "val_idx = dat['val_idx']\n",
    "repetitions = dat['repetitions']\n",
    "monkey_ids = dat['subject_id']\n",
    "image_ids = dat['image_ids']\n",
    "\n",
    "# normalize responses\n",
    "responses_nan = np.where(real_responses, responses, np.nan)\n",
    "resp_std = np.nanstd(responses_nan, axis=0)\n",
    "responses = responses / resp_std\n",
    "test_responses = test_responses / resp_std\n",
    "\n",
    "train_images = images[train_idx]\n",
    "val_images = images[val_idx]\n",
    "train_responses = responses[train_idx]\n",
    "val_responses = responses[val_idx]\n",
    "train_real_responses = real_responses[train_idx]\n",
    "val_real_responses = real_responses[val_idx]\n",
    "\n",
    "print('train:', train_images.shape, train_responses.shape, train_real_responses.shape)\n",
    "print('val:', val_images.shape, val_responses.shape, val_real_responses.shape)\n",
    "print('test:', test_images.shape, test_responses.shape, test_real_responses.shape)\n",
    "\n",
    "print('resp:', responses.min(), responses.max())\n",
    "print('test resp:', test_responses.min(), test_responses.max())\n",
    "\n",
    "test_responses = np.where(test_real_responses, test_responses, np.nan)\n",
    "\n",
    "NN = train_responses.shape[1]\n",
    "Lx, Ly = train_images.shape[2], train_images.shape[3]\n",
    "\n",
    "train_images = torch.from_numpy(train_images)\n",
    "val_images = torch.from_numpy(val_images)\n",
    "train_responses = torch.from_numpy(train_responses)\n",
    "val_responses = torch.from_numpy(val_responses)\n",
    "train_real_responses = torch.from_numpy(train_real_responses)\n",
    "val_real_responses = torch.from_numpy(val_real_responses)\n",
    "test_images = torch.from_numpy(test_images).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "seed = 2\n",
    "nlayers = 2\n",
    "nconv1 = 192\n",
    "nconv2 = 192\n",
    "n_max_neurons = 166\n",
    "feve_nlayers = np.zeros((4, n_max_neurons))\n",
    "weight_decay_core = 0.1\n",
    "seed = 1\n",
    "for nlayers in range(1, 5):\n",
    "    if nlayers == 3: weight_decay_core = 0.2\n",
    "    elif nlayers == 4: weight_decay_core = 0.3\n",
    "    else: weight_decay_core = 0.1\n",
    "\n",
    "    model, in_channels = model_builder.build_model(NN=166, n_layers=nlayers, n_conv=nconv1, n_conv_mid=nconv2, input_Lx=Lx, input_Ly=Ly)\n",
    "    if weight_decay_core != 0.1: suffix = f'wdcore_{weight_decay_core}'\n",
    "    else: suffix = ''\n",
    "    model_name = model_builder.create_model_name('monkeyV1', '2019', n_layers=nlayers, in_channels=in_channels, seed=seed, suffix=suffix)\n",
    "    weight_path = os.path.join(weight_path, 'fullmodel', 'monkeyV1')\n",
    "    model_path = os.path.join(weight_path, model_name)\n",
    "    print('model path: ', model_path)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print('loaded model', model_path)\n",
    "    model = model.to(device)\n",
    "\n",
    "    spks_pred_test = model_trainer.test_epoch(model, test_images)\n",
    "    test_fev, test_feve = metrics.monkey_feve(test_responses, spks_pred_test, repetitions)\n",
    "    print('FEVE (test): ', np.mean(test_feve))\n",
    "    feve_nlayers[nlayers-1] = test_feve\n",
    "\n",
    "    imonkey1 = np.where(monkey_ids == 4)[0] \n",
    "    imonkey2 = np.where(monkey_ids == 34)[0]\n",
    "\n",
    "    print('FEVE (test) monkey 1: ', np.mean(test_feve[imonkey1]))\n",
    "    print('FEVE (test) monkey 2: ', np.mean(test_feve[imonkey2]))\n",
    "    print('FEVE (test) mean: ', np.mean([np.mean(test_feve[imonkey1]), np.mean(test_feve[imonkey2])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['feve_depth'] = feve_nlayers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LN result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "seed = 1\n",
    "nlayers = 2\n",
    "nconv1 = 16\n",
    "nconv2 = 320\n",
    "n_max_neurons = 166\n",
    "seed = 1\n",
    "\n",
    "model, in_channels = model_builder.build_model(NN=166, n_layers=nlayers, n_conv=nconv1, n_conv_mid=nconv2, input_Lx=Lx, input_Ly=Ly, activation=None, avgpool=True)\n",
    "model_name = model_builder.create_model_name('monkeyV1', '2019', n_layers=nlayers, in_channels=in_channels, seed=seed, suffix='LN')\n",
    "weight_path = os.path.join(weight_path, 'LNmodel', 'monkeyV1')\n",
    "model_path = os.path.join(weight_path, model_name)\n",
    "print('model path: ', model_path)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "print('loaded model', model_path)\n",
    "model = model.to(device)\n",
    "\n",
    "model.eval()\n",
    "spks_pred_test = model_trainer.test_epoch(model, test_images)\n",
    "test_fev, test_feve = metrics.monkey_feve(test_responses, spks_pred_test, repetitions)\n",
    "print('FEVE (test): ', np.mean(test_feve))\n",
    "\n",
    "imonkey1 = np.where(monkey_ids == 4)[0] \n",
    "imonkey2 = np.where(monkey_ids == 34)[0]\n",
    "\n",
    "print('FEVE (test) monkey 1: ', np.mean(test_feve[imonkey1]))\n",
    "print('FEVE (test) monkey 2: ', np.mean(test_feve[imonkey2]))\n",
    "print('FEVE (test) mean: ', np.mean([np.mean(test_feve[imonkey1]), np.mean(test_feve[imonkey2])]))\n",
    "data_dict['LNmodel_feve_all'] = test_feve"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# change #conv1 #conv2 result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "nlayers = 2\n",
    "nconv1 = 192\n",
    "nconv2 = 192\n",
    "n_max_neurons = 166\n",
    "nconv1_list = [8,16,32,64, 128, 192, 256, 320, 384, 448]\n",
    "nconv2_list = [8,16,32,64, 128, 192, 256, 320, 384, 448]\n",
    "seed = 2\n",
    "feve_width = np.zeros((len(nconv1_list), len(nconv2_list), n_max_neurons))\n",
    "\n",
    "for i, nconv1 in enumerate(nconv1_list):\n",
    "    for j, nconv2 in enumerate(nconv2_list):\n",
    "        if (nconv1==16) and (nconv2==320) and(seed==1): continue\n",
    "        model, in_channels = model_builder.build_model(NN=166, n_layers=nlayers, n_conv=nconv1, n_conv_mid=nconv2, input_Lx=Lx, input_Ly=Ly)\n",
    "        model_name = model_builder.create_model_name('monkeyV1', '2019', n_layers=nlayers, in_channels=in_channels, seed=seed)\n",
    "        weight_path = os.path.join(weight_path, 'fullmodel', 'monkeyV1')\n",
    "        model_path = os.path.join(weight_path, model_name)\n",
    "        print('model path: ', model_path)\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        print('loaded model', model_path)\n",
    "        model = model.to(device)\n",
    "\n",
    "        spks_pred_test = model_trainer.test_epoch(model, test_images)\n",
    "        test_fev, test_feve = metrics.monkey_feve(test_responses, spks_pred_test, repetitions)\n",
    "        print('FEVE (test): ', np.mean(test_feve))\n",
    "        feve_width[i, j] = test_feve\n",
    "\n",
    "        imonkey1 = np.where(monkey_ids == 4)[0] \n",
    "        imonkey2 = np.where(monkey_ids == 34)[0]\n",
    "\n",
    "        print('FEVE (test) monkey 1: ', np.mean(test_feve[imonkey1]))\n",
    "        print('FEVE (test) monkey 2: ', np.mean(test_feve[imonkey2]))\n",
    "        print('FEVE (test) mean: ', np.mean([np.mean(test_feve[imonkey1]), np.mean(test_feve[imonkey2])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['feve_width'] = feve_width"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# change #stims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_max_stims = 4640\n",
    "stim_numbers = np.geomspace(500, n_max_stims, num=10, dtype=int)\n",
    "stim_numbers = np.unique(stim_numbers)  # Remove duplicates that might occur due to rounding\n",
    "print(stim_numbers)\n",
    "\n",
    "# build model\n",
    "seed = 1\n",
    "nlayers = 2\n",
    "nconv1 = 16\n",
    "nconv2 = 320\n",
    "n_max_neurons = 166\n",
    "feve_nstims = np.zeros((len(stim_numbers), n_max_neurons))\n",
    "\n",
    "for i, n_stim in enumerate(stim_numbers):\n",
    "    model, in_channels = model_builder.build_model(NN=n_max_neurons, n_layers=nlayers, n_conv=nconv1, n_conv_mid=nconv2, input_Lx=Lx, input_Ly=Ly)\n",
    "    suffix = f'nstims_{n_stim}'\n",
    "    model_name = model_builder.create_model_name('monkeyV1', '2019', n_layers=nlayers, in_channels=in_channels, seed=seed, suffix=suffix)   \n",
    "    weight_path = os.path.join(weight_path, 'fullmodel', 'monkeyV1')\n",
    "    model_path = os.path.join(weight_path, model_name)\n",
    "    print('model path: ', model_path)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print('loaded model', model_path)\n",
    "    model = model.to(device)\n",
    "\n",
    "    spks_pred_test = model_trainer.test_epoch(model, test_images)\n",
    "    test_fev, test_feve = metrics.monkey_feve(test_responses, spks_pred_test, repetitions)\n",
    "    print('FEVE (test): ', np.mean(test_feve))\n",
    "    feve_nstims[i] = test_feve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['nstims'] = stim_numbers\n",
    "data_dict['feve_nstims'] = feve_nstims"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# change #neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "seed = 1\n",
    "nlayers = 2\n",
    "nconv1 = 16\n",
    "nconv2 = 320\n",
    "n_max_neurons = 166\n",
    "feve_nneurons = []\n",
    "nneuron_monkey_ids = []\n",
    "\n",
    "#  Generate lists of neuron numbers and seed numbers using logarithmic spacing\n",
    "neuron_numbers = np.geomspace(1, n_max_neurons, num=10, dtype=int)\n",
    "neuron_numbers = np.unique(np.concatenate(([1], neuron_numbers)))  # Ensure 1 is included and remove duplicates\n",
    "seed_numbers = np.linspace(20, 1, num=len(neuron_numbers), dtype=int)\n",
    "for i, n_neuron in enumerate(neuron_numbers):\n",
    "    feve_nneurons.append([])\n",
    "    nneuron_monkey_ids.append([])\n",
    "    for seed in range(1, seed_numbers[i]+1):\n",
    "        ineurons = np.arange(166)\n",
    "        if n_neuron != n_max_neurons: \n",
    "            np.random.seed(n_neuron*seed)\n",
    "            ineurons = np.random.choice(np.arange(166), size=n_neuron, replace=False)\n",
    "\n",
    "        dat = np.load(os.path.join(data_path, 'monkeyv1_cadena_2019.npz'))\n",
    "        images = dat['images']\n",
    "        responses = dat['responses'][:, ineurons]\n",
    "        real_responses = dat['real_responses'][:, ineurons]\n",
    "        test_images = dat['test_images']\n",
    "        test_responses = dat['test_responses'][:, :, ineurons]\n",
    "        test_real_responses = dat['test_real_responses'][:, :, ineurons]\n",
    "        repetitions = dat['repetitions'][ineurons]\n",
    "        monkey_id = dat['subject_id'][ineurons]\n",
    "        image_ids = dat['image_ids']\n",
    "\n",
    "        # normalize responses\n",
    "        responses_nan = np.where(real_responses, responses, np.nan)\n",
    "        resp_std = np.nanstd(responses_nan, axis=0)\n",
    "        responses = responses / resp_std\n",
    "        test_responses = test_responses / resp_std\n",
    "\n",
    "        test_responses = np.where(test_real_responses, test_responses, np.nan)\n",
    "\n",
    "        model, in_channels = model_builder.build_model(NN=n_neuron, n_layers=nlayers, n_conv=nconv1, n_conv_mid=nconv2, input_Lx=Lx, input_Ly=Ly)\n",
    "        if n_neuron != n_max_neurons: suffix = f'nneurons_{n_neuron}'\n",
    "        else: suffix = ''\n",
    "        model_name = model_builder.create_model_name('monkeyV1', '2019', n_layers=nlayers, in_channels=in_channels, seed=seed, suffix=suffix)   \n",
    "        weight_path = os.path.join(weight_path, 'fullmodel', 'monkeyV1')\n",
    "        model_path = os.path.join(weight_path, model_name)\n",
    "        print('model path: ', model_path)\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        print('loaded model', model_path)\n",
    "        model = model.to(device)\n",
    "\n",
    "        test_images = torch.from_numpy(test_images).to(device)\n",
    "        spks_pred_test = model_trainer.test_epoch(model, test_images)\n",
    "        test_fev, test_feve = metrics.monkey_feve(test_responses, spks_pred_test, repetitions)\n",
    "        print('FEVE (test): ', np.mean(test_feve))\n",
    "        feve_nneurons[i].append(test_feve)\n",
    "\n",
    "        nneuron_monkey_ids[i].append(monkey_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['nneurons'] = neuron_numbers\n",
    "data_dict['feve_nneurons'] = feve_nneurons\n",
    "data_dict['nneuron_monkey_ids'] = nneuron_monkey_ids\n",
    "\n",
    "feves = np.zeros((2, len(neuron_numbers)))\n",
    "for i, nn in enumerate(neuron_numbers):\n",
    "    feve_allseed = np.array(feve_nneurons[i])\n",
    "    nseed = len(feve_allseed)\n",
    "    # print(feve_allseed.shape)\n",
    "    feve_tmp = np.zeros((2, nseed))\n",
    "    for iseed in range(nseed):\n",
    "        monkey_id = np.array(nneuron_monkey_ids[i][iseed])\n",
    "        imonkey1 = np.where(monkey_id == 4)[0]\n",
    "        imonkey2 = np.where(monkey_id == 34)[0]\n",
    "        feve = feve_allseed[iseed]\n",
    "        if len(imonkey1) == 0:\n",
    "            feve_tmp[0, iseed] = np.nan\n",
    "        else:\n",
    "            feve_tmp[0, iseed] = feve[imonkey1].mean()\n",
    "        if len(imonkey2) == 0:\n",
    "            feve_tmp[1, iseed] = np.nan\n",
    "        else:\n",
    "            feve_tmp[1, iseed] = feve[imonkey2].mean()\n",
    "\n",
    "    feves[0, i] = np.nanmean(feve_tmp[0])\n",
    "    feves[1, i] = np.nanmean(feve_tmp[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualize conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "nlayers = 2\n",
    "nconv1 = 16\n",
    "nconv2 = 320\n",
    "n_max_neurons = 166\n",
    "feve_nlayers = np.zeros((4, n_max_neurons))\n",
    "weight_decay_core = 0.1\n",
    "seed = 2\n",
    "\n",
    "model, in_channels = model_builder.build_model(NN=166, n_layers=nlayers, n_conv=nconv1, n_conv_mid=nconv2, input_Lx=Lx, input_Ly=Ly)\n",
    "if weight_decay_core != 0.1: suffix = f'wdcore_{weight_decay_core}'\n",
    "else: suffix = ''\n",
    "model_name = model_builder.create_model_name('monkeyV1', '2019', n_layers=nlayers, in_channels=in_channels, seed=seed, suffix=suffix)\n",
    "weight_path = os.path.join(weight_path, 'fullmodel', 'monkeyV1')\n",
    "model_path = os.path.join(weight_path, model_name)\n",
    "print('model path: ', model_path)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "print('loaded model', model_path)\n",
    "model = model.to(device)\n",
    "\n",
    "spks_pred_test = model_trainer.test_epoch(model, test_images)\n",
    "test_fev, test_feve = metrics.monkey_feve(test_responses, spks_pred_test, repetitions)\n",
    "print('FEVE (test): ', np.mean(test_feve))\n",
    "feve_nlayers[nlayers-1] = test_feve\n",
    "\n",
    "imonkey1 = np.where(monkey_ids == 4)[0] \n",
    "imonkey2 = np.where(monkey_ids == 34)[0]\n",
    "\n",
    "print('FEVE (test) monkey 1: ', np.mean(test_feve[imonkey1]))\n",
    "print('FEVE (test) monkey 2: ', np.mean(test_feve[imonkey2]))\n",
    "print('FEVE (test) mean: ', np.mean([np.mean(test_feve[imonkey1]), np.mean(test_feve[imonkey2])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['fev_all'] = test_fev\n",
    "data_dict['fullmodel_Wx'] = model.readout.Wx.cpu().detach().numpy().squeeze()\n",
    "data_dict['fullmodel_Wy'] = model.readout.Wy.cpu().detach().numpy().squeeze()\n",
    "data_dict['fullmodel_feve_all'] = test_feve\n",
    "data_dict['monkey_ids'] = monkey_ids"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('outputs/fullmodel_monkey_results.npz', **data_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
