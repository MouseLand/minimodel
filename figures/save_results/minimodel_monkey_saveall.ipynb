{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from minimodel import data, metrics, model_builder, model_trainer\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "data_dict = {}\n",
    "\n",
    "data_path = '../../data'\n",
    "weight_path = '../checkpoints/fullmodel'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# param search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ineuron = 1\n",
    "n_max_neurons = 166\n",
    "hs_list = [0.0, 0.0005, 0.001, 0.002, 0.003, 0.004, 0.005, 0.01, 0.02, 0.05]\n",
    "n_select_neurons = 10\n",
    "np.random.seed(1)\n",
    "ineurons = np.random.choice(n_max_neurons, n_select_neurons, replace=False)\n",
    "\n",
    "feve_test_all = np.zeros((len(hs_list), n_select_neurons))\n",
    "feve_val_all = np.zeros((len(hs_list), n_select_neurons))\n",
    "wc_all = np.zeros((len(hs_list), len(ineurons),  64))\n",
    "for i, hs_readout in enumerate(hs_list):\n",
    "    for j, ineuron in enumerate(ineurons):\n",
    "        # load data\n",
    "        dat = np.load(os.path.join(data_path, 'monkeyv1_cadena_2019.npz'))\n",
    "        images = dat['images']\n",
    "        responses = dat['responses'][:, ineuron][:, None]\n",
    "        real_responses = dat['real_responses'][:, ineuron][:, None]\n",
    "        test_images = dat['test_images']\n",
    "        test_responses = dat['test_responses'][:, :, ineuron][:, :, None]\n",
    "        test_real_responses = dat['test_real_responses'][:, :, ineuron][:, :, None]\n",
    "        train_idx = dat['train_idx']\n",
    "        val_idx = dat['val_idx']\n",
    "        repetitions = [dat['repetitions'][ineuron]]\n",
    "        monkey_id = dat['subject_id']\n",
    "\n",
    "        responses_nan = np.where(real_responses, responses, np.nan)\n",
    "        resp_std = np.nanstd(responses_nan, axis=0)\n",
    "        responses = responses / resp_std\n",
    "        test_responses = test_responses / resp_std\n",
    "\n",
    "\n",
    "        train_images = images[train_idx]\n",
    "        val_images = images[val_idx]\n",
    "        train_responses = responses[train_idx]\n",
    "        val_responses = responses[val_idx]\n",
    "        train_real_responses = real_responses[train_idx]\n",
    "        val_real_responses = real_responses[val_idx]\n",
    "\n",
    "        test_responses_nan = np.where(test_real_responses, test_responses, np.nan)\n",
    "\n",
    "        monkey_ids = dat['subject_id']\n",
    "        print(len(monkey_ids), np.unique(monkey_ids))\n",
    "\n",
    "        NN = train_responses.shape[1]\n",
    "        Lx, Ly = train_images.shape[2], train_images.shape[3]\n",
    "\n",
    "        train_images = torch.from_numpy(train_images)\n",
    "        val_images = torch.from_numpy(val_images)\n",
    "        train_responses = torch.from_numpy(train_responses)\n",
    "        val_responses = torch.from_numpy(val_responses)\n",
    "        train_real_responses = torch.from_numpy(train_real_responses)\n",
    "        val_real_responses = torch.from_numpy(val_real_responses)\n",
    "\n",
    "        # build model\n",
    "        seed = 1\n",
    "        nlayers = 2\n",
    "        nconv1 = 16\n",
    "        nconv2 = 64\n",
    "        wc_coef = 0.2\n",
    "        l2_readout = 0.2\n",
    "        \n",
    "        model, in_channels = model_builder.build_model(NN=1, n_layers=nlayers, n_conv=nconv1, n_conv_mid=nconv2, input_Lx=Lx, input_Ly=Ly, Wc_coef=wc_coef)\n",
    "        model_name = model_builder.create_model_name('monkeyV1', '2019', ineuron=ineuron, n_layers=nlayers, in_channels=in_channels, seed=seed, hs_readout=hs_readout)\n",
    "        weight_path = os.path.join(weight_path, 'minimodel', 'monkeyV1')\n",
    "        model_path = os.path.join(weight_path, model_name)\n",
    "        print('model path: ', model_path)\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        print('loaded model', model_path)\n",
    "        model = model.to(device)\n",
    "\n",
    "        test_images = torch.from_numpy(test_images).to(device)\n",
    "        spks_pred_test = model_trainer.test_epoch(model, test_images)\n",
    "\n",
    "        test_fev, test_feve = metrics.monkey_feve(test_responses, spks_pred_test, repetitions)\n",
    "        print('FEVE (test):', np.mean(test_feve))\n",
    "        feve_test_all[i, j] = test_feve\n",
    "\n",
    "        num_reps = 4\n",
    "        sz = val_responses.shape[0]\n",
    "        val_responses = val_responses.reshape([num_reps, int(sz / num_reps), NN])\n",
    "        val_images = val_images.reshape([num_reps, int(sz / num_reps), 1, 80, 80])[0]\n",
    "\n",
    "        val_images = val_images.to(device)\n",
    "        spks_pred_val = model_trainer.test_epoch(model, val_images)\n",
    "        val_fev, val_feve = metrics.monkey_feve(val_responses, spks_pred_val, repetitions)\n",
    "        print('FEVE (val):', np.mean(val_feve))\n",
    "        feve_val_all[i, j] = val_feve\n",
    "\n",
    "        wc_all[i, j] = model.readout.Wc.detach().cpu().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['param_search_feve_val'] = feve_val_all.mean(axis=1)\n",
    "data_dict['param_search_nconv2_val'] = np.sum(np.abs(wc_all)>0.01, axis=2).mean(axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# param search (all neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ineuron = 1\n",
    "hs_list = [0.0, 0.0005, 0.001, 0.002, 0.003, 0.004, 0.005, 0.01, 0.02, 0.05]\n",
    "feve_all = np.zeros((len(hs_list), 166))\n",
    "wc_all = np.zeros((len(hs_list), 166, 64))\n",
    "for i, hs_readout in enumerate(hs_list):\n",
    "    for ineuron in range(166):\n",
    "        # load data\n",
    "        dat = np.load(os.path.join(data_path, 'monkeyv1_cadena_2019.npz'))\n",
    "        images = dat['images']\n",
    "        responses = dat['responses'][:, ineuron][:, None]\n",
    "        real_responses = dat['real_responses'][:, ineuron][:, None]\n",
    "        test_images = dat['test_images']\n",
    "        test_responses = dat['test_responses'][:, :, ineuron][:, :, None]\n",
    "        test_real_responses = dat['test_real_responses'][:, :, ineuron][:, :, None]\n",
    "        train_idx = dat['train_idx']\n",
    "        val_idx = dat['val_idx']\n",
    "        repetitions = [dat['repetitions'][ineuron]]\n",
    "        monkey_id = dat['subject_id']\n",
    "\n",
    "\n",
    "        # normalize responses\n",
    "        responses_nan = np.where(real_responses, responses, np.nan)\n",
    "        resp_std = np.nanstd(responses_nan, axis=0)\n",
    "        responses = responses / resp_std\n",
    "        test_responses = test_responses / resp_std\n",
    "\n",
    "\n",
    "        train_images = images[train_idx]\n",
    "        val_images = images[val_idx]\n",
    "        train_responses = responses[train_idx]\n",
    "        val_responses = responses[val_idx]\n",
    "        train_real_responses = real_responses[train_idx]\n",
    "        val_real_responses = real_responses[val_idx]\n",
    "\n",
    "        test_responses = np.where(test_real_responses, test_responses, np.nan)\n",
    "\n",
    "        monkey_ids = dat['subject_id']\n",
    "        print(len(monkey_ids), np.unique(monkey_ids))\n",
    "\n",
    "        NN = train_responses.shape[1]\n",
    "        Lx, Ly = train_images.shape[2], train_images.shape[3]\n",
    "\n",
    "        train_images = torch.from_numpy(train_images)\n",
    "        val_images = torch.from_numpy(val_images)\n",
    "        train_responses = torch.from_numpy(train_responses)\n",
    "        val_responses = torch.from_numpy(val_responses)\n",
    "        train_real_responses = torch.from_numpy(train_real_responses)\n",
    "        val_real_responses = torch.from_numpy(val_real_responses)\n",
    "\n",
    "        # build model\n",
    "        seed = 1\n",
    "        nlayers = 2\n",
    "        nconv1 = 16\n",
    "        nconv2 = 64\n",
    "        wc_coef = 0.2\n",
    "        l2_readout = 0.2\n",
    "        model, in_channels = model_builder.build_model(NN=1, n_layers=nlayers, n_conv=nconv1, n_conv_mid=nconv2, input_Lx=Lx, input_Ly=Ly, Wc_coef=wc_coef)\n",
    "        model_name = model_builder.create_model_name('monkeyV1', '2019', ineuron=ineuron, n_layers=nlayers, in_channels=in_channels, seed=seed, \n",
    "                                            hs_readout=hs_readout)\n",
    "        weight_path = os.path.join(weight_path, 'minimodel', 'monkeyV1')\n",
    "        model_path = os.path.join(weight_path, model_name)\n",
    "        print('model path: ', model_path)\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        print('loaded model', model_path)\n",
    "        model = model.to(device)\n",
    "\n",
    "        test_images = torch.from_numpy(test_images).to(device)\n",
    "        spks_pred_test = model_trainer.test_epoch(model, test_images)\n",
    "\n",
    "        test_fev, test_feve = metrics.monkey_feve(test_responses, spks_pred_test, repetitions)\n",
    "        print('FEVE (test):', np.mean(test_feve))\n",
    "        feve_all[i, ineuron] = test_feve\n",
    "        wc_all[i, ineuron] = model.readout.Wc.detach().cpu().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['feve_hs_all'] = feve_all\n",
    "data_dict['wc_hs_all'] = wc_all\n",
    "data_dict['hs_list'] = hs_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load all neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ineuron = 1\n",
    "feve_all = np.zeros(166)\n",
    "fev_all = np.zeros(166)\n",
    "wc_all = np.zeros((166, 64))\n",
    "wx_all = []\n",
    "wy_all = []\n",
    "test_pred_all = []\n",
    "for ineuron in range(166):\n",
    "    # load data\n",
    "    dat = np.load(os.path.join(data_path, 'monkeyv1_cadena_2019.npz'))\n",
    "    images = dat['images']\n",
    "    responses = dat['responses'][:, ineuron][:, None]\n",
    "    real_responses = dat['real_responses'][:, ineuron][:, None]\n",
    "    test_images = dat['test_images']\n",
    "    test_responses = dat['test_responses'][:, :, ineuron][:, :, None]\n",
    "    test_real_responses = dat['test_real_responses'][:, :, ineuron][:, :, None]\n",
    "    train_idx = dat['train_idx']\n",
    "    val_idx = dat['val_idx']\n",
    "    repetitions = [dat['repetitions'][ineuron]]\n",
    "    monkey_id = dat['subject_id']\n",
    "\n",
    "\n",
    "    # normalize responses\n",
    "    responses_nan = np.where(real_responses, responses, np.nan)\n",
    "    resp_std = np.nanstd(responses_nan, axis=0)\n",
    "    responses = responses / resp_std\n",
    "    test_responses = test_responses / resp_std\n",
    "\n",
    "\n",
    "    train_images = images[train_idx]\n",
    "    val_images = images[val_idx]\n",
    "    train_responses = responses[train_idx]\n",
    "    val_responses = responses[val_idx]\n",
    "    train_real_responses = real_responses[train_idx]\n",
    "    val_real_responses = real_responses[val_idx]\n",
    "\n",
    "    test_responses = np.where(test_real_responses, test_responses, np.nan)\n",
    "\n",
    "    monkey_ids = dat['subject_id']\n",
    "    print(len(monkey_ids), np.unique(monkey_ids))\n",
    "\n",
    "    NN = train_responses.shape[1]\n",
    "    Lx, Ly = train_images.shape[2], train_images.shape[3]\n",
    "\n",
    "    train_images = torch.from_numpy(train_images)\n",
    "    val_images = torch.from_numpy(val_images)\n",
    "    train_responses = torch.from_numpy(train_responses)\n",
    "    val_responses = torch.from_numpy(val_responses)\n",
    "    train_real_responses = torch.from_numpy(train_real_responses)\n",
    "    val_real_responses = torch.from_numpy(val_real_responses)\n",
    "\n",
    "    # build model\n",
    "    seed = 1\n",
    "    nlayers = 2\n",
    "    nconv1 = 16\n",
    "    nconv2 = 64\n",
    "    wc_coef = 0.2\n",
    "    hs_readout = 0.004\n",
    "    l2_readout = 0.2\n",
    "    model, in_channels = model_builder.build_model(NN=1, n_layers=nlayers, n_conv=nconv1, n_conv_mid=nconv2, input_Lx=Lx, input_Ly=Ly, Wc_coef=wc_coef)\n",
    "    model_name = model_builder.create_model_name('monkeyV1', '2019', ineuron=ineuron, n_layers=nlayers, in_channels=in_channels, seed=seed, hs_readout=hs_readout)\n",
    "    weight_path = os.path.join(weight_path, 'minimodel', 'monkeyV1')\n",
    "    model_path = os.path.join(weight_path, model_name)\n",
    "    print('model path: ', model_path)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print('loaded model', model_path)\n",
    "    model = model.to(device)\n",
    "\n",
    "    test_images = torch.from_numpy(test_images).to(device)\n",
    "    spks_pred_test = model_trainer.test_epoch(model, test_images)\n",
    "    test_pred_all.append(spks_pred_test)\n",
    "\n",
    "    test_fev, test_feve = metrics.monkey_feve(test_responses, spks_pred_test, repetitions)\n",
    "    print('FEVE (test):', np.mean(test_feve))\n",
    "    feve_all[ineuron] = np.mean(test_feve)\n",
    "    fev_all[ineuron] = np.mean(test_fev)\n",
    "    wc_all[ineuron] = model.readout.Wc.detach().cpu().numpy().squeeze()\n",
    "    wx_all.append(model.readout.Wx.detach().cpu().numpy().squeeze())\n",
    "    wy_all.append(model.readout.Wy.detach().cpu().numpy().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['feve_all'] = feve_all\n",
    "data_dict['fev_all'] = fev_all\n",
    "data_dict['wc_all'] = wc_all\n",
    "data_dict['wx_all'] = np.stack(wx_all)\n",
    "data_dict['wy_all'] = np.stack(wy_all)\n",
    "data_dict['test_pred_all'] = np.stack(test_pred_all).squeeze()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"outputs/minimodel_monkey_result.npz\", **data_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
