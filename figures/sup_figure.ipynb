{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from minimodel import data, model_builder, metrics, model_trainer\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "data_dict = {}\n",
    "\n",
    "data_path = '../data'\n",
    "weight_path = './checkpoints/fullmodel'\n",
    "result_path = './save_results/outputs'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# figure 1: retinotopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "mouse_id = 0\n",
    "xpos_all = []\n",
    "ypos_all = []\n",
    "xpos_visual_all = []\n",
    "ypos_visual_all = []\n",
    "x_pixel_ratio = 0.75\n",
    "y_pixel_ratio = 0.5\n",
    "fev_all = []\n",
    "for mouse_id in range(6):\n",
    "    fname = '%s_nat60k_%s.npz'%(data.db[mouse_id]['mname'], data.db[mouse_id]['datexp'])\n",
    "    spks, istim_train, istim_test, xpos, ypos, spks_rep_all = data.load_neurons(file_path = os.path.join(data_path, fname), mouse_id = mouse_id)\n",
    "    xpos_all.append(xpos)\n",
    "    ypos_all.append(ypos)\n",
    "    dat = np.load(os.path.join(result_path, f'fullmodel_{data.mouse_names[mouse_id]}_results.npz'), allow_pickle=True)\n",
    "    from minimodel.utils import weight_bandwidth\n",
    "    Wx = dat['fullmodel_Wx']\n",
    "    Wy = dat['fullmodel_Wy']\n",
    "    NN = Wx.shape[0]\n",
    "    bandwidth_Wx = np.zeros(NN)\n",
    "    bandwidth_Wy = np.zeros(NN)\n",
    "    centerpos_Wx = np.zeros(NN)\n",
    "    centerpos_Wy = np.zeros(NN)\n",
    "    for i in range(NN):\n",
    "        bandwidth_Wx[i], centerpos_Wx[i] = weight_bandwidth(Wx[i, :], return_peak=True)\n",
    "        bandwidth_Wy[i], centerpos_Wy[i] = weight_bandwidth(Wy[i, :], return_peak=True)\n",
    "    xpos_model = np.argmax(Wx.squeeze(), axis=1) \n",
    "    ypos_model = np.argmax(Wy.squeeze(), axis=1) \n",
    "    xpos_visual = centerpos_Wx*2*(270/264) - 135 # 0 is at the center, so it should be 135 pixels\n",
    "    ypos_visual = centerpos_Wy*2*(65/66) - 32.5 # vertical visual range is 65, so it sould be (66/65) pixels per degree\n",
    "    if mouse_id == 5: xpos_visual += (46*270/264) # xrange of mouse 6 is 46-176\n",
    "    xpos = xpos / x_pixel_ratio\n",
    "    ypos = ypos / y_pixel_ratio\n",
    "    if mouse_id == 1:\n",
    "        idx_up = np.where(xpos>325/ x_pixel_ratio)[0]\n",
    "        idx_down = np.where(xpos<=325/ x_pixel_ratio)[0]\n",
    "        ymax = ypos[idx_up].max()\n",
    "        xmax, xmin = xpos[idx_up].max(), xpos[idx_up].min()\n",
    "        ypos[idx_up] = ymax - ypos[idx_up] +300 # + ymax\n",
    "    xpos_visual_all.append(xpos_visual)\n",
    "    ypos_visual_all.append(ypos_visual)\n",
    "    fev_all.append(dat['fev'])\n",
    "data_dict['xpos_all'] = np.array(xpos_all)\n",
    "data_dict['ypos_all'] = np.array(ypos_all)\n",
    "data_dict['xpos_visual_all'] = np.array(xpos_visual_all)\n",
    "data_dict['ypos_visual_all'] = np.array(ypos_visual_all)\n",
    "data_dict['fev_all'] = np.array(fev_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "db = []\n",
    "\n",
    "db.append({'mname': 'L1_A5', 'datexp': '2023_01_27', 'blk':'3', 'stim':'short3'})\n",
    "db.append({'mname': 'L1_A1', 'datexp': '2023_03_27', 'blk':'1', 'stim':'short3'})\n",
    "db.append({'mname': 'FX9', 'datexp': '2023_05_02', 'blk':'2', 'stim':'short3'})\n",
    "db.append({'mname': 'FX10', 'datexp': '2023_05_02', 'blk':'1', 'stim':'short3'})\n",
    "db.append({'mname': 'FX8', 'datexp': '2023_05_02', 'blk':'1', 'stim':'short3'})\n",
    "db.append({'mname': 'FX20', 'datexp': '2023_09_08', 'blk':'2','stim':'nat15k'})\n",
    "\n",
    "iregion_all = []\n",
    "iarea_all = []\n",
    "xy_all = []\n",
    "out_all = []\n",
    "jxy_all = []\n",
    "\n",
    "for i, mouse in enumerate(db[:6]):\n",
    "    aligned_path = Path(os.path.join(result_path, 'Ret_maps'))\n",
    "    aligned_path = aligned_path.joinpath(f\"{db[i]['mname']}_{db[i]['datexp']}_{db[i]['blk']}_{db[i]['stim']}.npz\")\n",
    "\n",
    "    m = np.load(aligned_path, allow_pickle=True)\n",
    "    iregion = m['iregion']\n",
    "    iarea = m['iarea']\n",
    "    xy = m['xy']\n",
    "    out = m['out']\n",
    "    jxy = m['jxy']\n",
    "    iregion_all.append(iregion)\n",
    "    iarea_all.append(iarea)\n",
    "    xy_all.append(xy)\n",
    "    out_all.append(out)\n",
    "    jxy_all.append(jxy)\n",
    "data_dict['iregion'] = np.array(iregion_all)\n",
    "data_dict['iarea'] = np.array(iarea_all)\n",
    "data_dict['xy'] = np.array(xy_all)  \n",
    "data_dict['out'] = np.array(out_all)\n",
    "data_dict['jxy'] = np.array(jxy_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sup_figure\n",
    "from fig_utils import *\n",
    "save_path = './outputs'\n",
    "sup_figure.figure1(data_dict, save_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# figure 2: signal variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example neuron Trial 1 vs trial 2\n",
    "mouse_id = 1\n",
    "fname = '%s_nat60k_%s.npz'%(data.db[mouse_id]['mname'], data.db[mouse_id]['datexp'])\n",
    "spks, istim_train, istim_test, xpos, ypos, spks_rep_all = data.load_neurons(file_path = os.path.join(data_path, fname), mouse_id = mouse_id)\n",
    "# spks, spks_rep, itrain, ival, fev, istim_test = load_activity(file_path=mouse_file_paths[mouse_id], mouse_id=mouse_id)\n",
    "# split train and validation set\n",
    "itrain, ival = data.split_train_val(istim_train, train_frac=0.9)\n",
    "# normalize spks\n",
    "spks, spks_rep_all = data.normalize_spks(spks, spks_rep_all, itrain)\n",
    "fev_all = metrics.fev(spks_rep_all)\n",
    "\n",
    "ineurons = [2550, 5020, 264]\n",
    "spks_rep = [spks_rep_all[i][:,ineurons] for i in range(len(spks_rep_all))]\n",
    "data_dict['example_repeats'] = np.stack(spks_rep)\n",
    "data_dict['example_fev'] = fev_all[ineurons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signal variance distribution mouse\n",
    "fev_all = []\n",
    "for mouse_id in range(6):\n",
    "    dat = np.load(os.path.join(result_path, f'fullmodel_{data.mouse_names[mouse_id]}_results.npz'), allow_pickle=True)\n",
    "    fev_all.append(dat['fev'])\n",
    "fev_all = np.hstack(fev_all)\n",
    "data_dict['fev_all'] = fev_all"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## monkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "dat = np.load(os.path.join(data_path, 'monkeyv1_cadena_2019.npz'))\n",
    "images = dat['images']\n",
    "responses = dat['responses']\n",
    "real_responses = dat['real_responses']\n",
    "test_images = dat['test_images']\n",
    "test_responses = dat['test_responses']\n",
    "test_real_responses = dat['test_real_responses']\n",
    "train_idx = dat['train_idx']\n",
    "val_idx = dat['val_idx']\n",
    "repetitions = dat['repetitions']\n",
    "monkey_ids = dat['subject_id']\n",
    "image_ids = dat['image_ids']\n",
    "\n",
    "# normalize responses\n",
    "responses_nan = np.where(real_responses, responses, np.nan)\n",
    "resp_std = np.nanstd(responses_nan, axis=0)\n",
    "responses = responses / resp_std\n",
    "test_responses = test_responses / resp_std\n",
    "\n",
    "test_responses_nan = np.where(test_real_responses, test_responses, np.nan)\n",
    "print('test_responses_nan: ', test_responses_nan.shape)\n",
    "\n",
    "# spks_test_mean = np.nanmean(test_responses_nan, axis=0)\n",
    "# print(spks_test_mean.shape)\n",
    "dat = np.load(os.path.join(result_path, f'fullmodel_monkey_results.npz'), allow_pickle=True)\n",
    "data_dict['monkey_fev_all'] = dat['fev_all']\n",
    "ineurons = [51, 105, 86]\n",
    "data_dict['monkey_example_repeats'] = test_responses_nan[:, :, ineurons]\n",
    "data_dict['monkey_example_fev'] = dat['fev_all'][ineurons]\n",
    "data_dict['monkey_example_reps'] = repetitions[ineurons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ineurons = [51, 105, 86]\n",
    "data_dict['monkey_example_repeats'] = test_responses_nan[:, :, ineurons]\n",
    "data_dict['monkey_example_fev'] = dat['fev_all'][ineurons]\n",
    "data_dict['monkey_example_reps'] = repetitions[ineurons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sup_figure\n",
    "from fig_utils import *\n",
    "save_path = './outputs'\n",
    "sup_figure.figure2(data_dict, save_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# figure 3: Wx and Wy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mouse\n",
    "# Example neuron Trial 1 vs trial 2\n",
    "mouse_id = 0\n",
    "Wx_all = []\n",
    "Wy_all = []\n",
    "fev_all = []\n",
    "for mouse_id in range(6):\n",
    "    # spks, spks_rep, itrain, ival, fev, istim_test = load_activity(file_path=data.mouse_file_paths[mouse_id], mouse_id=mouse_id)\n",
    "    n_neurons = data.NNs[mouse_id]\n",
    "    ineur = np.arange(0, n_neurons) #np.arange(0, n_neurons, 5)\n",
    "    input_Ly, input_Lx = 66, 130\n",
    "    nlayers = 2\n",
    "    nconv1 = 192\n",
    "    nconv2 = 192\n",
    "\n",
    "    suffix = ''\n",
    "    if mouse_id == 5: suffix += f'xrange_176'\n",
    "    model, in_channels = model_builder.build_model(NN=len(ineur), n_layers=nlayers, n_conv=nconv1, n_conv_mid=nconv2, pool=pool, depth_separable=depth_separable)\n",
    "    model_name = model_builder.create_model_name(data.mouse_names[mouse_id], data.exp_date[mouse_id], n_layers=nlayers, in_channels=in_channels, clamp=clamp, suffix=suffix)\n",
    "\n",
    "    weight_path = os.path.join(weight_path, 'fullmodel', data.mouse_names[mouse_id])\n",
    "    if not os.path.exists(weight_path):\n",
    "        os.makedirs(weight_path)\n",
    "    model_path = os.path.join(weight_path, model_name)\n",
    "    print('model path: ', model_path)\n",
    "    model = model.to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print('loaded model', model_path)\n",
    "\n",
    "    Wc = model.readout.Wc.detach().cpu().numpy().squeeze()\n",
    "    # # change model Wx and Wy\n",
    "    Wx = model.readout.Wx.detach().cpu().numpy()\n",
    "    Wy = model.readout.Wy.detach().cpu().numpy()\n",
    "    # outer product of Wx and Wy\n",
    "    Wxy = np.einsum('icj,ick->ijk', Wy, Wx)\n",
    "\n",
    "    dat = np.load(os.path.join(result_path, f'fullmodel_{data.mouse_names[mouse_id]}_results.npz'), allow_pickle=True)\n",
    "    fev = dat['fev']\n",
    "    valid_idx = np.where(fev > 0.15)[0]\n",
    "    Wx_all.append(Wx[valid_idx])\n",
    "    Wy_all.append(Wy[valid_idx])\n",
    "    fev_all.append(fev[valid_idx])\n",
    "\n",
    "data_dict['fev_all'] = fev_all\n",
    "data_dict['Wx_all'] = Wx_all\n",
    "data_dict['Wy_all'] = Wy_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minimodel.utils import weight_bandwidth\n",
    "from scipy.interpolate import interp1d\n",
    "fev_all = data_dict['fev_all']\n",
    "Wx_all = data_dict['Wx_all']\n",
    "Wy_all = data_dict['Wy_all']\n",
    "\n",
    "fev = np.hstack(fev_all)\n",
    "Wx = np.vstack(Wx_all)\n",
    "Wy = np.vstack(Wy_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = Wx.shape[0]\n",
    "bandwidth_Wx = np.zeros(NN)\n",
    "bandwidth_Wy = np.zeros(NN)\n",
    "centerpos_Wx = np.zeros(NN)\n",
    "centerpos_Wy = np.zeros(NN)\n",
    "for i in range(NN):\n",
    "    bandwidth_Wx[i], centerpos_Wx[i] = weight_bandwidth(Wx[i, 0, :], return_peak=True)\n",
    "    bandwidth_Wy[i], centerpos_Wy[i] = weight_bandwidth(Wy[i, 0, :], return_peak=True)\n",
    "\n",
    "Lx, Ly = Wx.shape[-1], Wy.shape[-1]\n",
    "xmid, ymid = int(Lx/2), int(Ly/2)\n",
    "x_xrange, y_xrange = np.arange(Lx), np.arange(Ly)\n",
    "\n",
    "ineurons = np.arange(0, NN)\n",
    "# Define a common x range for interpolation, e.g., based on the min and max of x_xrange and center positions\n",
    "common_x = np.linspace(np.min(x_xrange - np.max(centerpos_Wx)), \n",
    "                    np.max(x_xrange - np.min(centerpos_Wx)), \n",
    "                    num=len(x_xrange))\n",
    "\n",
    "# Container for interpolated Wx values\n",
    "interp_Wx_values = []\n",
    "\n",
    "for i in ineurons:\n",
    "    # Original x values for this neuron, shifted by its center position\n",
    "    original_x = x_xrange - centerpos_Wx[i]\n",
    "    # Interpolation function for the current neuron's Wx values\n",
    "    interp_func = interp1d(original_x, Wx[i, 0, :], kind='linear', bounds_error=False, fill_value=np.NaN)\n",
    "    # Interpolate onto the common x range and store the result\n",
    "    interp_Wx_values.append(interp_func(common_x))\n",
    "    # plt.plot(original_x, Wx[i, 0, :], color='whitesmoke', alpha=1/255)\n",
    "\n",
    "\n",
    "data_dict['interp_Wx_values'] = interp_Wx_values\n",
    "data_dict['common_x'] = common_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Assumptions and initial setup (Ensure these variables are defined correctly in your context)\n",
    "ineurons = np.arange(0, NN)\n",
    "# Define a common x range for interpolation, e.g., based on the min and max of x_xrange and center positions\n",
    "common_x = np.linspace(np.min(y_xrange - np.max(centerpos_Wy)), \n",
    "                       np.max(y_xrange - np.min(centerpos_Wy)), \n",
    "                       num=len(y_xrange))\n",
    "\n",
    "# Container for interpolated Wx values\n",
    "interp_Wy_values = []\n",
    "\n",
    "for i in ineurons:\n",
    "    # Original x values for this neuron, shifted by its center position\n",
    "    original_x = y_xrange - centerpos_Wy[i]\n",
    "    # Interpolation function for the current neuron's Wx values\n",
    "    interp_func = interp1d(original_x, Wy[i, 0, :], kind='linear', bounds_error=False, fill_value=np.NaN)\n",
    "    # Interpolate onto the common x range and store the result\n",
    "    interp_Wy_values.append(interp_func(common_x))\n",
    "    # plt.plot(original_x, Wy[i, 0, :], color='gray', alpha=0.1)\n",
    "\n",
    "# Calculate the mean of the interpolated Wx values\n",
    "data_dict['interp_Wy_values'] = interp_Wy_values\n",
    "data_dict['common_y'] = common_x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## monkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monkey\n",
    "Lx, Ly = 80, 80\n",
    "nconv1 = 192\n",
    "nconv2 = 192\n",
    "use_sensorium_normalization = True\n",
    "model, in_channels = model_builder.build_model(NN=166, n_layers=nlayers, n_conv=nconv1, n_conv_mid=nconv2, input_Lx=Lx, input_Ly=Ly)\n",
    "suffix = ''\n",
    "model_name = model_builder.create_model_name('monkeyV1', '2019', n_layers=nlayers, in_channels=in_channels, suffix=suffix, seed=1, use_sensorium_normalization=use_sensorium_normalization)\n",
    "weight_path = os.path.join(weight_path, 'fullmodel', 'monkeyV1')\n",
    "model_path = os.path.join(weight_path, model_name)\n",
    "print('model path: ', model_path)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "print('loaded model', model_path)\n",
    "model = model.to(device)\n",
    "\n",
    "Wc = model.readout.Wc.detach().cpu().numpy().squeeze()\n",
    "# # change model Wx and Wy\n",
    "Wx = model.readout.Wx.detach().cpu().numpy()\n",
    "Wy = model.readout.Wy.detach().cpu().numpy()\n",
    "# outer product of Wx and Wy\n",
    "Wxy = np.einsum('icj,ick->ijk', Wy, Wx)\n",
    "print(Wxy.shape, Wc.shape)\n",
    "print(Wc.shape, Wc.min(), Wc.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = Wx.shape[0]\n",
    "bandwidth_Wx = np.zeros(NN)\n",
    "bandwidth_Wy = np.zeros(NN)\n",
    "centerpos_Wx = np.zeros(NN)\n",
    "centerpos_Wy = np.zeros(NN)\n",
    "for i in range(NN):\n",
    "    bandwidth_Wx[i], centerpos_Wx[i] = weight_bandwidth(Wx[i, 0, :], return_peak=True)\n",
    "    bandwidth_Wy[i], centerpos_Wy[i] = weight_bandwidth(Wy[i, 0, :], return_peak=True)\n",
    "\n",
    "Lx, Ly = Wx.shape[-1], Wy.shape[-1]\n",
    "xmid, ymid = int(Lx/2), int(Ly/2)\n",
    "x_xrange, y_xrange = np.arange(Lx), np.arange(Ly)\n",
    "\n",
    "ineurons = np.arange(0, NN)\n",
    "# Define a common x range for interpolation, e.g., based on the min and max of x_xrange and center positions\n",
    "common_x = np.linspace(np.min(x_xrange - np.max(centerpos_Wx)), \n",
    "                    np.max(x_xrange - np.min(centerpos_Wx)), \n",
    "                    num=len(x_xrange))\n",
    "\n",
    "# Container for interpolated Wx values\n",
    "interp_Wx_values = []\n",
    "\n",
    "for i in ineurons:\n",
    "    # Original x values for this neuron, shifted by its center position\n",
    "    original_x = x_xrange - centerpos_Wx[i]\n",
    "    # Interpolation function for the current neuron's Wx values\n",
    "    interp_func = interp1d(original_x, Wx[i, 0, :], kind='linear', bounds_error=False, fill_value=np.NaN)\n",
    "    # Interpolate onto the common x range and store the result\n",
    "    interp_Wx_values.append(interp_func(common_x))\n",
    "    # plt.plot(original_x, Wx[i, 0, :], color='whitesmoke', alpha=1/255)\n",
    "\n",
    "\n",
    "data_dict['monkey_interp_Wx_values'] = interp_Wx_values\n",
    "data_dict['monkey_common_x'] = common_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Assumptions and initial setup (Ensure these variables are defined correctly in your context)\n",
    "ineurons = np.arange(0, NN)\n",
    "# Define a common x range for interpolation, e.g., based on the min and max of x_xrange and center positions\n",
    "common_x = np.linspace(np.min(y_xrange - np.max(centerpos_Wy)), \n",
    "                       np.max(y_xrange - np.min(centerpos_Wy)), \n",
    "                       num=len(y_xrange))\n",
    "\n",
    "# Container for interpolated Wx values\n",
    "interp_Wy_values = []\n",
    "\n",
    "for i in ineurons:\n",
    "    # Original x values for this neuron, shifted by its center position\n",
    "    original_x = y_xrange - centerpos_Wy[i]\n",
    "    # Interpolation function for the current neuron's Wx values\n",
    "    interp_func = interp1d(original_x, Wy[i, 0, :], kind='linear', bounds_error=False, fill_value=np.NaN)\n",
    "    # Interpolate onto the common x range and store the result\n",
    "    interp_Wy_values.append(interp_func(common_x))\n",
    "    # plt.plot(original_x, Wy[i, 0, :], color='gray', alpha=0.1)\n",
    "\n",
    "# Calculate the mean of the interpolated Wx values\n",
    "data_dict['monkey_interp_Wy_values'] = interp_Wy_values\n",
    "data_dict['monkey_common_y'] = common_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "import sup_figure\n",
    "from fig_utils import *\n",
    "save_path = './outputs'\n",
    "sup_figure.figure3(data_dict, save_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# figure 4: sparsity penalty on minimodel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mouse validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_id = 0\n",
    "hs_list = [0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.2, 0.5]\n",
    "nhs = len(hs_list)\n",
    "feve_all = []\n",
    "nconv2_all = []\n",
    "\n",
    "dat = np.load(os.path.join(result_path, f'{data.mouse_names[mouse_id]}_{data.exp_date[mouse_id]}_minimodel_16_64_choose_param_val_result.npz'))\n",
    "feve_all = dat['feve_val']\n",
    "nconv2_all = dat['nconv2']\n",
    "print(feve_all.shape, nconv2_all.shape)\n",
    "\n",
    "data_dict['mouse_feve_val'] = feve_all\n",
    "data_dict['mouse_nconv2_val'] = nconv2_all\n",
    "\n",
    "dat = np.load(os.path.join(result_path, f'{data.mouse_names[mouse_id]}_{data.exp_date[mouse_id]}_minimodel_16_64_choose_param_5k_val_result.npz'))\n",
    "feve_all = dat['feve_val']\n",
    "nconv2_all = dat['nconv2']\n",
    "print(feve_all.shape, nconv2_all.shape)\n",
    "\n",
    "data_dict['mouse_feve_val_5k'] = feve_all\n",
    "data_dict['mouse_nconv2_val_5k'] = nconv2_all\n",
    "\n",
    "# monkey\n",
    "dat = np.load(\"outputs/minimodel_monkey_result.npz\")\n",
    "feve_all = dat['param_search_feve_val']\n",
    "nconv2_all = dat['param_search_nconv2_val']\n",
    "print(feve_all.shape, nconv2_all.shape)\n",
    "\n",
    "data_dict['monkey_feve_val'] = feve_all\n",
    "data_dict['monkey_nconv2_val'] = nconv2_all"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mouse test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmouse = 6\n",
    "hs_list = [0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.2, 0.5]\n",
    "nhs = len(hs_list)\n",
    "feve_all = []\n",
    "nconv2_all = []\n",
    "for mouse_id in range(nmouse):\n",
    "    dat = np.load(os.path.join(result_path, f'{data.mouse_names[mouse_id]}_{data.exp_date[mouse_id]}_minimodel_16_64_choose_param_result.npz'))\n",
    "    feve = dat['feve_all']\n",
    "    wc = dat['wc_all']\n",
    "    nconv2 = np.sum(np.abs(wc)>0.01, axis=2)\n",
    "    feve_all.append(feve)\n",
    "    nconv2_all.append(nconv2)\n",
    "feve_all = np.vstack(feve_all)\n",
    "nconv2_all = np.vstack(nconv2_all)\n",
    "print(feve_all.shape, nconv2_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['sparsity_feve_all'] = feve_all\n",
    "data_dict['sparsity_nconv2_all'] = nconv2_all\n",
    "data_dict['sparsity_hs'] = hs_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mouse 5k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmouse = 6\n",
    "hs_list = [0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.2, 0.5]\n",
    "nhs = len(hs_list)\n",
    "feve_all = []\n",
    "nconv2_all = []\n",
    "for mouse_id in range(nmouse):\n",
    "    dat = np.load(os.path.join(result_path, f'{data.mouse_names[mouse_id]}_{data.exp_date[mouse_id]}_minimodel_16_64_choose_param_5k_result.npz'))\n",
    "    feve = dat['feve_all']\n",
    "    wc = dat['wc_all']\n",
    "    nconv2 = np.sum(np.abs(wc)>0.01, axis=2)\n",
    "    feve_all.append(feve)\n",
    "    nconv2_all.append(nconv2)\n",
    "feve_all = np.vstack(feve_all)\n",
    "nconv2_all = np.vstack(nconv2_all)\n",
    "print(feve_all.shape, nconv2_all.shape)\n",
    "\n",
    "data_dict['sparsity_feve_5k_all'] = feve_all\n",
    "data_dict['sparsity_nconv2_5k_all'] = nconv2_all"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## monkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = np.load(os.path.join(result_path, 'minimodel_monkey_result.npz'))\n",
    "feve_hs_all = dat['feve_hs_all']\n",
    "wc_hs_all = dat['wc_hs_all']\n",
    "nconv2_all = np.sum(np.abs(wc_hs_all)>0.01, axis=2)\n",
    "hs_list = dat['hs_list']\n",
    "data_dict['sparsity_monkey_feve_all'] = feve_hs_all \n",
    "data_dict['sparsity_monkey_nconv2_all'] = nconv2_all\n",
    "data_dict['sparsity_monkey_hs'] = hs_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "import sup_figure\n",
    "from fig_utils import *\n",
    "save_path = './outputs'\n",
    "sup_figure.figure4(data_dict, save_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# figure 5: model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sup_figure\n",
    "from fig_utils import *\n",
    "save_path = './outputs'\n",
    "sup_figure.figure5(data_dict, save_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# figure 6: reuse conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmouse = 6\n",
    "NN = 100\n",
    "feve_matrix = np.zeros((nmouse, nmouse, NN))\n",
    "\n",
    "nconv1 = 16\n",
    "nconv2 = 64\n",
    "wc_coef = 0.2\n",
    "hs_readout = 0.03\n",
    "nlayers = 2\n",
    "\n",
    "for mouse_id in range(nmouse):\n",
    "    img = data.load_images(data_path, mouse_id, file=os.path.join(data_path, data.img_file_name[mouse_id]))\n",
    "    nimg, Ly, Lx = img.shape\n",
    "    print('img: ', img.shape, img.min(), img.max(), img.dtype)\n",
    "    fname = '%s_nat60k_%s.npz'%(data.db[mouse_id]['mname'], data.db[mouse_id]['datexp'])\n",
    "\n",
    "    spks, istim_train, istim_test, xpos, ypos, spks_rep_all = data.load_neurons(file_path = os.path.join(data_path, fname), mouse_id = mouse_id)\n",
    "    n_stim, n_max_neurons = spks.shape\n",
    "\n",
    "    # normalize spks\n",
    "    itrain, ival = data.split_train_val(istim_train, train_frac=0.9)\n",
    "    spks, spks_rep_all = data.normalize_spks(spks, spks_rep_all, itrain)\n",
    "    img_test = torch.from_numpy(img[istim_test]).to(device).unsqueeze(1)\n",
    "    input_Ly, input_Lx = img_test.shape[-2:]\n",
    "\n",
    "    ineurons = np.arange(data.NNs_valid[mouse_id])\n",
    "    np.random.seed(42)\n",
    "    ineurons = np.random.choice(ineurons, 100, replace=False)\n",
    "\n",
    "    fev_test = metrics.fev(spks_rep_all)\n",
    "    isort_neurons = np.argsort(fev_test)[::-1]\n",
    "    for mouse_id_base in range(nmouse):\n",
    "        for i, ineuron in enumerate(ineurons):\n",
    "            ineur = [isort_neurons[ineuron]]\n",
    "            spks_rep = [spks_rep_all[i][:,ineur] for i in range(len(spks_rep_all))]\n",
    "\n",
    "            if mouse_id_base != mouse_id:\n",
    "                suffix = f'pretrainconv1_{data.mouse_names[mouse_id_base]}_{data.exp_date[mouse_id_base]}'\n",
    "                if mouse_id_base == 5: \n",
    "                    suffix = f'pretrainconv1_{data.mouse_names[mouse_id_base]}_{data.exp_date[mouse_id_base]}_xrange_176'\n",
    "            else: \n",
    "                suffix = ''\n",
    "            model, in_channels = model_builder.build_model(NN=1, n_layers=nlayers, n_conv=nconv1, n_conv_mid=nconv2, Wc_coef=wc_coef)\n",
    "            model_name = model_builder.create_model_name(data.mouse_names[mouse_id], data.exp_date[mouse_id], ineuron=ineur[0], n_layers=nlayers, in_channels=in_channels, hs_readout=hs_readout, suffix=suffix)\n",
    "\n",
    "            weight_path = os.path.join(weight_path, 'minimodel', data.mouse_names[mouse_id])\n",
    "            model_path = os.path.join(weight_path, model_name)\n",
    "            print('model path: ', model_path)\n",
    "            model.load_state_dict(torch.load(model_path))\n",
    "            print('loaded model', model_path)\n",
    "            model = model.to(device)\n",
    "\n",
    "            # test model\n",
    "            test_pred = model_trainer.test_epoch(model, img_test)\n",
    "            test_fev, test_feve = metrics.feve(spks_rep, test_pred)\n",
    "            print('FEVE (test): ', test_feve)\n",
    "\n",
    "            feve_matrix[mouse_id, mouse_id_base, i] = np.mean(test_feve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['reuse_conv1_feve'] = feve_matrix.transpose(1,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv1 kernels\n",
    "mouse_id = 0\n",
    "conv1_all = []\n",
    "for mouse_id in range(6):\n",
    "    dat = np.load(os.path.join(result_path, f'fullmodel_{data.mouse_names[mouse_id]}_results.npz'), allow_pickle=True)\n",
    "    conv1 = dat['fullmodel_conv1_W']\n",
    "    conv1_all.append(conv1)\n",
    "data_dict['conv1_W'] = np.stack(conv1_all)\n",
    "print(data_dict['conv1_W'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sup_figure\n",
    "from fig_utils import *\n",
    "save_path = './outputs'\n",
    "sup_figure.figure6(data_dict, save_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# figure 7: example neurons visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sup_figure\n",
    "from fig_utils import *\n",
    "save_path = './outputs'\n",
    "sup_figure.figure9(data_dict, save_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(f'supfig_results.npz', **data_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
