{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data for Figure 2\n",
    "\n",
    "This notebook saves the processed data needed to plot **Figure 2** into a `.npz` file and then generates the corresponding plots.\n",
    "\n",
    "**Important:**  \n",
    "Before running this notebook, please make sure to execute the following notebooks in the `./save_results` directory. \n",
    "- [fullmodel_mouse_saveall.ipynb](https://github.com/MouseLand/minimodel/blob/main/figures/save_results/fullmodel_mouse_saveall.ipynb)\n",
    "- [fullmodel_monkey_saveall.ipynb](https://github.com/MouseLand/minimodel/blob/main/figures/save_results/fullmodel_monkey_saveall.ipynb)\n",
    "\n",
    "These notebooks:\n",
    "- Load the raw neural and stimulus data,\n",
    "- Run models for each animal (mouse and monkey),\n",
    "- Save the model outputs needed for plotting.\n",
    "\n",
    "Each notebook in `./save_results` corresponds to a specific condition or model variant. Skipping any of them may result in missing or incomplete data when running this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from minimodel import data\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "data_dict = {}\n",
    "\n",
    "data_path = '../data'\n",
    "weight_path = './checkpoints/fullmodel'\n",
    "result_path = './save_results/outputs'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# figure 2b-d (performance change with width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nconv1_list = [8, 16, 32, 64, 128, 192, 256, 320, 384, 448]\n",
    "nconv2_list = [8, 16, 32, 64, 128, 192, 256, 320, 384, 448]\n",
    "feve_width = []\n",
    "for mouse_id in range(6):\n",
    "    dat = np.load(os.path.join(result_path, f'fullmodel_{data.mouse_names[mouse_id]}_results.npz'), allow_pickle=True)\n",
    "    feve_width.append(dat['feve_width'].mean(axis=2))\n",
    "\n",
    "feve_width = np.stack(feve_width)\n",
    "data_dict['feve_our_model_vary_width'] = feve_width\n",
    "data_dict['nconv1'] = nconv1_list\n",
    "data_dict['nconv2'] = nconv2_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# figure 1e (conv1 kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images\n",
    "mouse_id = 0\n",
    "dat = np.load(os.path.join(result_path, f'fullmodel_{data.mouse_names[mouse_id]}_results.npz'), allow_pickle=True)\n",
    "data_dict['conv1_W'] = dat['fullmodel_conv1_W']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  monkey"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## figure 1f-g (performance change with width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = np.load(os.path.join(result_path, f'fullmodel_monkey_results.npz'), allow_pickle=True)\n",
    "data_dict['monkey_all_width_eve'] = dat['feve_width'].mean(axis=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## figure 2i (kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images\n",
    "mouse_id = 0\n",
    "dat = np.load(os.path.join(result_path, f'fullmodel_monkey_results.npz'), allow_pickle=True)\n",
    "data_dict['monkey_conv1_W'] = dat['conv1_W']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_W = data_dict['monkey_conv1_W']\n",
    "isort = [0,1,11,9,5,8,13,7,4,6,12,14,15,10,2,3]\n",
    "fig, ax = plt.subplots(4,4, figsize=(8, 8))\n",
    "for i in range(16):\n",
    "    ax[i//4, i%4].imshow(conv1_W[isort[i]], cmap='RdBu_r', vmin=-0.15, vmax=0.15)\n",
    "    # ax[i//4, i%4].set_title(f'{conv1_W_ratio[isort[i]]:.2f}')\n",
    "    ax[i//4, i%4].axis('off')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# figure 2k-l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texturenet_acc = np.load(os.path.join(result_path, 'texturenet_accuracy.npy'), allow_pickle=True)[()]['accuracy']\n",
    "imagenet_accuracy = np.load(os.path.join(result_path, 'top1_top5_summary.npy'), allow_pickle=True)[()]['top1']\n",
    "data_dict['texturenet_accuracy'] = texturenet_acc\n",
    "data_dict['imagenet_accuracy'] = imagenet_accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(f'figure2_results.npz', **data_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import figure2\n",
    "dat = np.load('figure2_results.npz', allow_pickle=True)\n",
    "save_path = './outputs'\n",
    "figure2.figure2(dat, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
