{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from minimodel import data, metrics\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "data_path = '../notebooks/data'\n",
    "weight_path = './checkpoints/fullmodel'\n",
    "result_path = './save_results/outputs'\n",
    "\n",
    "mouse_id = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train gabor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load neurons\n",
    "fname = '%s_nat60k_%s.npz'%(data.db[mouse_id]['mname'], data.db[mouse_id]['datexp'])\n",
    "spks, istim_train, istim_test, xpos, ypos, spks_rep_all = data.load_neurons(file_path = os.path.join(data_path, fname), mouse_id = mouse_id)\n",
    "n_stim, n_max_neurons = spks.shape\n",
    "\n",
    "# split train and validation set\n",
    "itrain, ival = data.split_train_val(istim_train, train_frac=0.9)\n",
    "ineur = np.arange(0, n_max_neurons) #np.arange(0, n_neurons, 5)\n",
    "\n",
    "# normalize spks\n",
    "spks, spks_rep_all = data.normalize_spks(spks, spks_rep_all, itrain)\n",
    "spks_val = torch.from_numpy(spks[ival][:,ineur]) \n",
    "spks_rep_all = [spks_rep_all[i][:,ineur] for i in range(len(spks_rep_all))]\n",
    "\n",
    "ineurons = np.arange(data.NNs_valid[mouse_id])\n",
    "# np.random.seed(42)\n",
    "# ineurons = np.random.choice(ineurons, 100, replace=False)\n",
    "\n",
    "fev_test = metrics.fev(spks_rep_all)\n",
    "isort_neurons = np.argsort(fev_test)[::-1]\n",
    "ineur = isort_neurons[ineurons]\n",
    "\n",
    "print(spks.shape, spks_val.shape, len(spks_rep_all), spks_rep_all[0].shape)\n",
    "\n",
    "spks = spks[:,ineur]\n",
    "spks_val = spks_val[:,ineur]\n",
    "spks_rep_all = [spks_rep_all[i][:,ineur] for i in range(len(spks_rep_all))]\n",
    "print(spks.shape, spks_val.shape, len(spks_rep_all), spks_rep_all[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_all = data.load_images(data_path, mouse_id, file=data.img_file_name[mouse_id], downsample=2)\n",
    "nimg, Ly, Lx = img_all.shape\n",
    "print('img: ', img_all.shape, img_all.min(), img_all.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_stim = -1 # spks.shape[0]\n",
    "n_neurons = -1\n",
    "\n",
    "# generate random data\n",
    "if n_stim > 0:\n",
    "    istims = np.random.choice(spks.shape[0], n_stim, replace=False)\n",
    "else:\n",
    "    n_stim = spks.shape[0]\n",
    "    istims = np.arange(n_stim)\n",
    "if n_neurons > 0:\n",
    "    ineurons = np.random.choice(spks.shape[1], n_neurons, replace=False)\n",
    "    X_test = [spks_rep_all[i][:,ineurons] for i in range(len(spks_rep_all))]\n",
    "else:\n",
    "    n_neurons = spks.shape[1]\n",
    "    ineurons = np.arange(n_neurons)\n",
    "    X_test = spks_rep_all.copy()\n",
    "\n",
    "X = spks[istims][:,ineurons]\n",
    "img = img_all[istim_train][istims].transpose(1,2,0)\n",
    "img_test = img_all[istim_test].transpose(1,2,0)\n",
    "print(f'img: {img.shape}, X: {X.shape}')\n",
    "Ly, Lx, _ = img.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minimodel import gabor\n",
    "result_dict = gabor.fit_gabor_model(X, img, X_test, img_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define gabor parameters\n",
    "sigma = np.array([0.75, 1.25, 1.5, 2.5, 3.5, 4.5, 5.5])\n",
    "f = np.array([0.1, 0.25, 0.5, 1, 2]) #[.01:.02:.13];\n",
    "theta = np.arange(0, np.pi, np.pi/8)\n",
    "ph = np.arange(0, 2*np.pi, np.pi/4)\n",
    "ar = np.array([1, 1.5, 2])\n",
    "print(f'sigma: {sigma.shape}, f: {f.shape}, theta: {theta.shape}, ph: {ph.shape}, ar: {ar.shape}')\n",
    "\n",
    "params = np.meshgrid(sigma, f, theta, ph, ar, indexing='ij')\n",
    "n_gabors = params[0].size\n",
    "print(f'number of gabors: {n_gabors}')\n",
    "\n",
    "for i in range(len(params)):\n",
    "    params[i] = np.expand_dims(params[i], axis=(-2,-1))\n",
    "    params[i] = torch.from_numpy(params[i].astype('float32'))\n",
    "sigma, f, theta, ph, ar = params\n",
    "print(f'sigma: {sigma.shape}, f: {f.shape}, theta: {theta.shape}, ph: {ph.shape}, ar: {ar.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = np.load(os.path.join(weight_path, 'gabor', f'gabor_params_{data.db[mouse_id][\"mname\"]}.npz'), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmax, ymax = result_dict['xmax'], result_dict['ymax']\n",
    "ys, xs = np.meshgrid(np.arange(0,Ly), np.arange(0,Lx), indexing='ij')\n",
    "ys, xs = torch.from_numpy(ys.astype('float32')), torch.from_numpy(xs.astype('float32'))\n",
    "gmax = result_dict['gmax']\n",
    "gabor_params = torch.zeros((5, n_neurons, 1, 1))\n",
    "for i in range(len(gabor_params)):\n",
    "    gabor_params[i] = params[i].flatten()[gmax].reshape(n_neurons, 1, 1)\n",
    "msigma, mf, mtheta, mph, mar = gabor_params\n",
    "Amax = result_dict['Amax']\n",
    "mu1 = torch.from_numpy(result_dict['mu1']).to(device)\n",
    "mu2 = torch.from_numpy(result_dict['mu2']).to(device)\n",
    "#  test\n",
    "ym = torch.from_numpy(ymax.astype('float32')).unsqueeze(-1).unsqueeze(-1)\n",
    "xm = torch.from_numpy(xmax.astype('float32')).unsqueeze(-1).unsqueeze(-1)\n",
    "# print(f'ym: {ym.shape}, xm: {xm.shape}')\n",
    "gabor_params = torch.zeros((5, n_neurons, 1, 1))\n",
    "for i in range(len(gabor_params)):\n",
    "    gabor_params[i] = params[i].flatten()[gmax].reshape(n_neurons, 1, 1)\n",
    "msigma, mf, mtheta, mph, mar = gabor_params\n",
    "from minimodel.gabor import gabor_filter, eval_gabors\n",
    "gabor_filters1 = gabor_filter(ys, xs, ym, xm, 1, msigma, mf, mtheta, mph, mar, is_torch=True).to(device).unsqueeze(-3)\n",
    "gabor_filters2 = gabor_filter(ys, xs, ym, xm, 1, msigma, mf, mtheta, mph + np.pi/2, mar, is_torch=True).to(device).unsqueeze(-3)\n",
    "\n",
    "# load test images\n",
    "# img_test = img_all[istim_test].transpose(1,2,0)\n",
    "# img_test = (img_test - img_mean) / img_std\n",
    "# print(f'img_test: {img_test.shape} {img_test.min()}, {img_test.max()}')\n",
    "\n",
    "# predict responses\n",
    "ntest = len(istim_test)\n",
    "resp_test1 = torch.zeros((n_neurons, ntest), dtype=torch.float32, device=device)\n",
    "resp_test2 = torch.zeros((n_neurons, ntest), dtype=torch.float32, device=device)\n",
    "eval_gabors(img_test, gabor_filters1, resp_test1, device=device, rectify=False)\n",
    "eval_gabors(img_test, gabor_filters2, resp_test2, device=device, rectify=False)\n",
    "resp_test2 = torch.sqrt(resp_test1**2 + resp_test2**2) # RMS for complex cell response\n",
    "from torch.nn.functional import relu\n",
    "resp_test2 = relu(resp_test2) # rectify\n",
    "resp_test1 = relu(resp_test1) # rectify\n",
    "\n",
    "c = torch.from_numpy(Amax).to(device)\n",
    "\n",
    "rpred = ((resp_test1.T - mu1) * c[:,0] + (resp_test2.T - mu2) * c[:,1]) # (n_stim, n_neurons)\n",
    "print(f'rpred: {rpred.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test responses\n",
    "train_mu = result_dict['train_mu']\n",
    "train_std = result_dict['train_std']\n",
    "X_test = [spks_rep_all[i][:,ineurons] for i in range(len(spks_rep_all))]\n",
    "for i in range(len(X_test)):\n",
    "    X_test[i] -= train_mu\n",
    "    X_test[i] /= train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fev, feve = metrics.feve(X_test, rpred.cpu().numpy())\n",
    "print(f'fev:{fev.mean():.3f}, feve:{feve.mean():.3f}')\n",
    "\n",
    "cratio = Amax[:,1]/Amax.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gabor_filters1.shape\n",
    "ineurons = np.random.choice(n_neurons, 10, replace=False)\n",
    "import matplotlib.pyplot as plt \n",
    "fig, ax = plt.subplots(2, 5, figsize=(15,6))\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    axi.imshow(gabor_filters1[ineurons[i]].cpu().numpy().squeeze(), cmap='gray')\n",
    "    axi.axis('off')\n",
    "    axi.set_title(f'sigma={msigma[ineurons[i]].item():.2f}, f={mf[ineurons[i]].item():.2f}, \\ntheta={mtheta[ineurons[i]].item():.2f}, ph={mph[ineurons[i]].item():.2f}, \\nar={mar[ineurons[i]].item():.2f}')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
