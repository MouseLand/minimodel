{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data for Figure 4\n",
    "\n",
    "This notebook saves the processed data needed to plot **Figure 4** into a `.npz` file and then generates the corresponding plots.\n",
    "\n",
    "**Important:**  \n",
    "Before running this notebook, please make sure to execute the following notebooks in the `./save_results` directory. \n",
    "- [minimodel_mouse_saveall.ipynb](https://github.com/MouseLand/minimodel/blob/main/figures/save_results/minimodel_mouse_saveall.ipynb)\n",
    "- [minimodel_monkey_saveall.ipynb](https://github.com/MouseLand/minimodel/blob/main/figures/save_results/minimodel_monkey_saveall.ipynb)\n",
    "- [mouse_invariance_saveall.ipynb](https://github.com/MouseLand/minimodel/blob/main/figures/save_results/mouse_invariance_saveall.ipynb)\n",
    "- [monkey_invariance_saveall.ipynb](https://github.com/MouseLand/minimodel/blob/main/figures/save_results/monkey_invariance_saveall.ipynb)\n",
    "\n",
    "These notebooks:\n",
    "- Load the raw neural and stimulus data,\n",
    "- Run models for each animal (mouse and monkey),\n",
    "- Save the model outputs needed for plotting.\n",
    "\n",
    "Each notebook in `./save_results` corresponds to a specific condition or model variant. Skipping any of them may result in missing or incomplete data when running this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from minimodel import data\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "data_dict = {}\n",
    "\n",
    "data_path = '../data'\n",
    "weight_path = './checkpoints/fullmodel'\n",
    "result_path = './save_results/outputs'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# figure 4a visualize texture 16 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_id = 2\n",
    "# load images\n",
    "img = data.load_images(data_path, mouse_id, file=os.path.join(data_path, data.img_file_name[mouse_id]), normalize=False, crop=False)\n",
    "nimg, Ly, Lx = img.shape\n",
    "print('img: ', img.shape, img.min(), img.max(), img.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, Ly, Lx = img.shape\n",
    "img_transpose = img[60000:].transpose(1,2,0)\n",
    "Ly, Lx, N = img_transpose.shape\n",
    "nimg = 5\n",
    "ids = [0,5000,6500, 2, 7000]\n",
    "# get texture classes, 16 classes each has 500 images\n",
    "ncls = 16\n",
    "cls_ids = np.arange(ncls)[:, np.newaxis].repeat(500, axis=1).flatten() + 1 # starts with 1\n",
    "xpad = int(15)\n",
    "ypad = int(35)\n",
    "pimg = np.ones((Ly+(nimg-1)*ypad, Lx+(nimg-1)*ypad)) * 255\n",
    "for i,idd in enumerate(ids):\n",
    "    pimg[i*ypad:(i*ypad+Ly), i*xpad:(i*xpad+Lx)] = img_transpose[:,:,idd]\n",
    "    # print(cls_ids[idd])\n",
    "data_dict['dataset_imgs'] = pimg\n",
    "data_dict['dataset_img_ids'] = cls_ids[ids]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# figure 4b decoding accuracy change with NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from approxineuro.neural_utils import texture_accuracy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "n_seeds = 10\n",
    "n_mouse = 4\n",
    "n_neurons_list = np.logspace(0, 4, 20).astype(int)[1:-3]\n",
    "print(n_neurons_list)\n",
    "all_accs = np.zeros((n_mouse, len(n_neurons_list), n_seeds))\n",
    "all_neuron_accs = np.zeros(n_mouse)\n",
    "for m, mouse_id in enumerate([2,3,4,5]):\n",
    "    fname = 'text16_%s_%s.npz'%(data.db[mouse_id]['mname'], data.db[mouse_id]['datexp'])\n",
    "    dat = np.load(os.path.join(data_path fname), allow_pickle=True)  \n",
    "    txt16_spks = dat['sp']\n",
    "    txt16_istim = dat['istim'].astype(int)\n",
    "    txt16_labels = dat['labels']\n",
    "    txt16_test_istim = dat['ss_istim'].astype(int)\n",
    "    txt16_test_labels = dat['ss_labels']\n",
    "    txt16_test_spks = np.stack(dat['ss_all']).mean(1)\n",
    "    print('train spks:', txt16_spks.shape, 'test spks:', txt16_test_spks.shape)\n",
    "    from scipy.stats import zscore\n",
    "    txt16_spks_zscore = zscore(txt16_spks, axis=1)\n",
    "    txt16_img = img[txt16_istim]\n",
    "\n",
    "    allneuron_acc = texture_accuracy(txt16_spks.T, txt16_labels, txt16_test_spks, txt16_test_labels)\n",
    "    print(f'accuracy of all neurons: {allneuron_acc:.2f}')\n",
    "    all_neuron_accs[m] = allneuron_acc\n",
    "\n",
    "    NN = txt16_spks.shape[0]\n",
    "    n_classes = len(np.unique(txt16_labels))\n",
    "    selected_classes = np.random.choice(np.arange(16), n_classes, replace=False)\n",
    "    selected_idxes_train = np.where(np.isin(txt16_labels, selected_classes))[0]\n",
    "    selected_idxes_test = np.where(np.isin(txt16_test_labels, selected_classes))[0]\n",
    "    \n",
    "    for k, n_neurons in enumerate(n_neurons_list):\n",
    "        for iseed, seed in enumerate(range(n_seeds)):\n",
    "            np.random.seed(42*m+seed)\n",
    "            random_ineurons = np.random.choice(NN, n_neurons, replace=False)\n",
    "            train_X = txt16_spks[random_ineurons][:, selected_idxes_train].T\n",
    "            train_y = txt16_labels[selected_idxes_train]\n",
    "            test_X = txt16_test_spks[selected_idxes_test][:, random_ineurons]\n",
    "            test_y = txt16_test_labels[selected_idxes_test]\n",
    "            mean_x = train_X.mean(axis=0)\n",
    "            std_x = train_X.std(axis=0)\n",
    "            train_X = (train_X - mean_x) / std_x\n",
    "            test_X = (test_X - mean_x) / std_x\n",
    "            clf = LogisticRegression(random_state=0, penalty='l2', C=0.1).fit(train_X, train_y)\n",
    "            acc = clf.score(test_X, test_y)\n",
    "            all_accs[m, k, iseed] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['n_neurons'] = n_neurons_list\n",
    "data_dict['classification_accs'] = all_accs\n",
    "data_dict['all_neuron_accs'] = all_neuron_accs\n",
    "print(all_neuron_accs.mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# figure 3c visualize catvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_id = 3\n",
    "# load txt16 data\n",
    "fname = 'text16_%s_%s.npz'%(data.db[mouse_id]['mname'], data.db[mouse_id]['datexp'])\n",
    "dat = np.load(os.path.join(data_path, fname), allow_pickle=True)\n",
    "txt16_spks_test = dat['ss_all']\n",
    "nstim, nrep, nneuron = txt16_spks_test.shape\n",
    "txt16_istim_test = dat['ss_istim'].astype(int)\n",
    "txt16_istim_test = np.repeat(txt16_istim_test[:, np.newaxis], nrep, axis=1).flatten()\n",
    "txt16_spks_test = txt16_spks_test.reshape(-1, nneuron)\n",
    "txt16_labels_test = dat['ss_labels']\n",
    "txt16_labels_test = np.repeat(txt16_labels_test[:, np.newaxis], nrep, axis=1).flatten()\n",
    "\n",
    "print('txt16_spks_test shape:', txt16_spks_test.shape)\n",
    "print('txt16_labels_test shape:', txt16_labels_test.shape)\n",
    "\n",
    "\n",
    "txt16_spks_train = dat['sp'].T\n",
    "txt16_istim_train = dat['istim'].astype(int)\n",
    "txt16_labels_train = dat['labels']\n",
    "\n",
    "print('txt16_spks_train shape:', txt16_spks_train.shape)\n",
    "print('txt16_labels_train shape:', txt16_labels_train.shape)\n",
    "\n",
    "txt16_spks = np.vstack((txt16_spks_train, txt16_spks_test))\n",
    "txt16_labels = np.hstack((txt16_labels_train, txt16_labels_test))\n",
    "txt16_istim = np.hstack((txt16_istim_train, txt16_istim_test))\n",
    "\n",
    "print('txt16_spks shape:', txt16_spks.shape)\n",
    "print('txt16_labels shape:', txt16_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import metrics\n",
    "iclass1 = 6\n",
    "iclass2 = 15\n",
    "catvar = metrics.category_variance_pairwise(txt16_spks.T, txt16_labels, ss=[iclass1, iclass2])\n",
    "print(np.mean(catvar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isort = np.argsort(catvar)[::-1]\n",
    "print(catvar.shape)\n",
    "\n",
    "i=1\n",
    "ineurons = isort[i:i+2]\n",
    "print(catvar[ineurons])\n",
    "neuron_spks = txt16_spks_test[:, ineurons].T\n",
    "neuron_spks /= neuron_spks.std(1)[:, np.newaxis]\n",
    "\n",
    "print(neuron_spks.shape)\n",
    "\n",
    "unique_istims_cls1 = np.unique(txt16_istim_test[txt16_labels_test == iclass1])\n",
    "unique_istims_cls2 = np.unique(txt16_istim_test[txt16_labels_test == iclass2])\n",
    "\n",
    "data_dict['example_istim_cls1'] = unique_istims_cls1\n",
    "data_dict['example_istim_cls2'] = unique_istims_cls2\n",
    "data_dict['example_neuron_spks'] = neuron_spks\n",
    "data_dict['example_ineuron'] = ineurons\n",
    "data_dict['example_classes'] = np.array([iclass1, iclass2])\n",
    "data_dict['txt16_istim_test'] = txt16_istim_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# figure 4d-g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_idxes_all = []\n",
    "pos_corr_all = []\n",
    "noisy_catvar_all = []\n",
    "neural_catvar_all = []\n",
    "model_catvar_all = []\n",
    "model_rfsize_all = []\n",
    "pred_catvar_all = []\n",
    "\n",
    "mouse_id = 2\n",
    "for mouse_id in [2,3,4,5]:\n",
    "    fpath = os.path.join(result_path, f'catvar_{data.db[mouse_id][\"mname\"]}_result.npz')\n",
    "    dat = np.load(fpath, allow_pickle=True)\n",
    "\n",
    "    valid_idxes = dat['valid_ineurons']\n",
    "    pos_corr = dat['mean_correlation']\n",
    "    noisy_catvar = dat['noisy_model_catvar']\n",
    "    neural_catvar = dat['neural_catvar'][dat['valid_ineurons']]\n",
    "    model_catvar = dat['model_catvar']\n",
    "    pred_catvar = dat['pred_catvar']\n",
    "    data_dict['op_all'] = dat['op_names']\n",
    "\n",
    "    valid_idxes_all.append(valid_idxes)\n",
    "    pos_corr_all.append(pos_corr)\n",
    "    noisy_catvar_all.append(noisy_catvar)\n",
    "    neural_catvar_all.append(neural_catvar)\n",
    "    model_catvar_all.append(model_catvar)\n",
    "    pred_catvar_all.append(pred_catvar)\n",
    "\n",
    "    # rfsize from the Wxy\n",
    "    dat = np.load(f'outputs/minimodel_{data.mouse_names[mouse_id]}_result.npz', allow_pickle=True)\n",
    "    Wx = dat['wx_all']\n",
    "    Wy = dat['wy_all']\n",
    "    feve = dat['feve_all']\n",
    "    high_feve_idxes = np.where(feve > 0.7)[0]\n",
    "    from minimodel.utils import weight_bandwidth\n",
    "    Wxy = np.einsum('ij,ik->ijk', Wy, Wx)\n",
    "    NN = Wxy.shape[0]\n",
    "    bandwidth_Wx = np.zeros(NN)\n",
    "    bandwidth_Wy = np.zeros(NN)\n",
    "    for i in range(NN):\n",
    "        bandwidth_Wx[i] = weight_bandwidth(Wx[i, :])\n",
    "        bandwidth_Wy[i] = weight_bandwidth(Wy[i, :])\n",
    "    rf_size = bandwidth_Wx * bandwidth_Wy\n",
    "    model_rfsize_all.append(rf_size[high_feve_idxes])\n",
    "\n",
    "data_dict['valid_idxes'] = valid_idxes_all\n",
    "data_dict['minimodel_poscorr_all'] = np.hstack(pos_corr_all)\n",
    "data_dict['minimodel_catvar_noise_all'] = np.hstack(noisy_catvar_all)\n",
    "data_dict['neural_catvar_all'] = np.hstack(neural_catvar_all)\n",
    "data_dict['minimodel_catvar_all'] = np.vstack(model_catvar_all)\n",
    "data_dict['rfsize'] = np.hstack(model_rfsize_all)\n",
    "data_dict['pred_catvar_all'] = np.hstack(pred_catvar_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('minimodel poscorr all:', data_dict['minimodel_poscorr_all'].shape)\n",
    "print('minimodel catvar noise all:', data_dict['minimodel_catvar_noise_all'].shape)\n",
    "print('neural catvar all:', data_dict['neural_catvar_all'].shape)\n",
    "print('minimodel catvar all:', data_dict['minimodel_catvar_all'].shape)\n",
    "print('rfsize:', data_dict['rfsize'].shape)\n",
    "print('pred catvar all:', data_dict['pred_catvar_all'].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# figure 4h-j monkey catvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = os.path.join(result_path, f'catvar_monkey_result.npz')\n",
    "dat = np.load(fpath, allow_pickle=True)\n",
    "\n",
    "data_dict['monkey_op_all'] = dat['op_names']\n",
    "data_dict['monkey_minimodel_catvar_all'] = dat['model_catvar']\n",
    "data_dict['monkey_minimodel_poscorr_all'] = dat['mean_correlation']\n",
    "data_dict['monkey_op_all'] = dat['op_names']\n",
    "data_dict['monkey_catvar_all'] = dat['model_catvar']     \n",
    "data_dict['monkey_pred_catvar'] = dat['pred_catvar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfsize from the Wxy\n",
    "dat = np.load(os.path.join(result_path, f'minimodel_monkey_result.npz'), allow_pickle=True)\n",
    "Wx = dat['wx_all']\n",
    "Wy = dat['wy_all']\n",
    "from minimodel.utils import weight_bandwidth\n",
    "Wxy = np.einsum('ij,ik->ijk', Wy, Wx)\n",
    "NN = Wxy.shape[0]\n",
    "bandwidth_Wx = np.zeros(NN)\n",
    "bandwidth_Wy = np.zeros(NN)\n",
    "for i in range(NN):\n",
    "    bandwidth_Wx[i] = weight_bandwidth(Wx[i, :])\n",
    "    bandwidth_Wy[i] = weight_bandwidth(Wy[i, :])\n",
    "rf_size = bandwidth_Wx * bandwidth_Wy\n",
    "data_dict['monkey_rfsize'] = rf_size\n",
    "# rfsize = np.pi * rfsize * (1.1/80)**2\n",
    "\n",
    "feve_all = dat['feve_all']\n",
    "data_dict['monkey_feve'] = feve_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_all = ['conv1', 'conv1(ReLU)', 'conv1(pool)', 'conv2(1x1)', 'conv2(spatial)', 'conv2(ReLU)', 'readout(Wxy)', 'readout(ELU)']\n",
    "data_dict['op_all'] = op_all"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data_dict\n",
    "np.savez(f'figure4_results.npz', **data_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import figure4\n",
    "dat = np.load('figure4_results.npz', allow_pickle=True)\n",
    "save_path = './outputs'\n",
    "figure4.figure4(dat, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
